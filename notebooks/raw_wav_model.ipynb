{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "raw_wav_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMaeGDHqdHzl",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow speech recognition challenge (Kaggle)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9M1eQyP_RQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from collections import Counter\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import Input, layers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6l9tyPj9S9x",
        "colab_type": "code",
        "outputId": "74e2b201-7104-4185-e9a4-426df9a0e94e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrnMmqcsAJEW",
        "colab_type": "code",
        "outputId": "ff812e21-d1d7-4fd5-8682-2cf031b05d45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "data_path = \"drive/My Drive/Colab Notebooks/data/preprocessed\"\n",
        "os.listdir(data_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample_submission.csv',\n",
              " 'wav_all.npy',\n",
              " 'label_all.npy',\n",
              " 'unknown_wav.npy',\n",
              " 'background_wav.npy',\n",
              " 'test_wav_final.npy',\n",
              " 'model-089-0.875049.h5',\n",
              " 'submission.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdeRLsS3Aaaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wav_all = np.load(os.path.join(data_path, \"wav_all.npy\"), allow_pickle=True)\n",
        "wav_all = np.array([list(arr) for arr in wav_all])\n",
        "\n",
        "label_all = np.load(os.path.join(data_path, \"label_all.npy\")).reshape(-1)\n",
        "\n",
        "unknown_wav = np.load(os.path.join(data_path, \"unknown_wav.npy\"))\n",
        "background_wav = np.load(os.path.join(data_path, \"background_wav.npy\"), allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEgnocZwA8Q7",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Generating training data\n",
        "#### Generating silence samples from background noise\n",
        "Since we have around 2131 of every label in our dataset, we will generate 2131 additional samples from background noise (and label it silence, because it doesn't contain any speech)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sKyApoLEPbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_silence_samples = 41115"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4z49YjgDoi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_noise_sample(noise_num=0):\n",
        "    \"\"\"Gets random sample from selected noise type (one out of 6)\"\"\"\n",
        "    selected_noise = background_wav[noise_num]\n",
        "    start_idx = random.randint(0, len(selected_noise)- 1 - 8000)\n",
        "    return selected_noise[start_idx:(start_idx + 8000)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldySn_SqFCai",
        "colab_type": "code",
        "outputId": "b5bada5c-7d9f-4a27-cccb-cc8850f424ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#silence audio\n",
        "silence_wav = []\n",
        "n_samples_per_noise = n_silence_samples // len(background_wav)\n",
        "for i, _ in enumerate(background_wav):\n",
        "    for _ in range(n_samples_per_noise):\n",
        "        silence_wav.append(get_noise_sample(i))\n",
        "silence_wav = np.array(silence_wav)\n",
        "silence_label = np.array(['silence' for _ in range(n_samples_per_noise * len(background_wav))])\n",
        "silence_wav.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41112, 8000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KtadH5iFOu5",
        "colab_type": "text"
      },
      "source": [
        "#### Creating samples of unknown speech\n",
        "Samples form all other labels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpH4Zqt1Fjzv",
        "colab_type": "code",
        "outputId": "a5c5f760-2c8a-42b7-af69-5bc5e6f84231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "unknown_wav.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41115, 8000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebywyxujHEZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unknown_wav = np.array(random.sample(list(unknown_wav), n_silence_samples))\n",
        "unknown_label = [\"unknown\" for _ in range(n_silence_samples)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8nsEtO5JJ2w",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "#### Data Processing pipeline\n",
        "The next step would be to create data processing pipeline: sample elements from the whole dataset instead of choosing fixed set of unknown samples and also doing data aumentation (mixing with noise) when doing training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXM5QZ6hJhPJ",
        "colab_type": "code",
        "outputId": "004a3e6f-9a64-4cc1-80cb-b3507708e03c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "unknown_wav.shape, wav_all.shape, silence_wav.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((41115, 8000), (21312, 8000), (41112, 8000))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZSQlPQVCipn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.concatenate([wav_all, unknown_wav, silence_wav], 0)\n",
        "labels = np.concatenate([label_all, unknown_label, silence_label], 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyT-BUDxCkpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del(wav_all)\n",
        "del(unknown_wav)\n",
        "del(silence_wav)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXUToZx6BZ8q",
        "colab_type": "code",
        "outputId": "9cbc8125-e8ab-4f7b-e65a-11addc84a810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "# Converting labels to one hot vectors\n",
        "label_values = np.unique(labels)\n",
        "label_dict = {label: value for value, label in enumerate(sorted(label_values))}\n",
        "label_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'down': 0,\n",
              " 'go': 1,\n",
              " 'left': 2,\n",
              " 'no': 3,\n",
              " 'off': 4,\n",
              " 'on': 5,\n",
              " 'right': 6,\n",
              " 'silence': 7,\n",
              " 'stop': 8,\n",
              " 'unknown': 9,\n",
              " 'up': 10,\n",
              " 'yes': 11}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAartyPsJ4r4",
        "colab_type": "code",
        "outputId": "aab20c32-a023-457a-f671-a7a02c3d9df8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "label_all = [label_dict[label] for label in labels]\n",
        "label_all = keras.utils.to_categorical(label_all, len(label_dict)).reshape(-1, 12, 1)\n",
        "label_all.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(103539, 12, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMxG6LXuAdK2",
        "colab_type": "code",
        "outputId": "6b0434bb-d36f-4665-f336-54ce0b0b189a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data.shape, labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((103539, 8000), (103539,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9IlnW8DAZ-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_wav, test_wav, train_label, test_label = train_test_split(data, label_all, test_size=0.2, random_state=42, shuffle=True)\n",
        "del(data)  # saving RAM space"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c_SLtMJxBLI",
        "colab_type": "code",
        "outputId": "d43bfc5b-fe8f-47f4-b574-a83ab50ed816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_label.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82831, 12, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wu9UB-P6FY6",
        "colab_type": "code",
        "outputId": "6927e809-0cf0-4120-d617-10b451be7324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train = tf.data.Dataset.from_tensor_slices(train_wav)\n",
        "y_train = tf.data.Dataset.from_tensor_slices(train_label.reshape([-1, 12]))\n",
        "\n",
        "x_test = tf.data.Dataset.from_tensor_slices(test_wav)\n",
        "y_test = tf.data.Dataset.from_tensor_slices(test_label.reshape([-1, 12]))\n",
        "\n",
        "next(iter(y_test)).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzX4DUFeXyCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_noise_sample(noise_num=0):\n",
        "    \"\"\"Gets random sample from selected noise type (one out of 6)\"\"\"\n",
        "    selected_noise = background_wav[noise_num]\n",
        "    start_idx = random.randint(0, len(selected_noise)- 1 - 8000)\n",
        "    return selected_noise[start_idx:(start_idx + 8000)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1JFm_4s61Hi",
        "colab_type": "code",
        "outputId": "e711b3e1-3c6d-4f76-af1b-722e2c085271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Defining data augmentation pipeline\n",
        "\n",
        "def augment_convert(x):\n",
        "    noise_ratio = random.random() / 2\n",
        "    num = random.randint(0, 5)\n",
        "    noise = get_noise_sample(num)\n",
        "    noised_x = x + noise_ratio * noise\n",
        "    return tf.reshape(noised_x, [8000, 1])\n",
        "\n",
        "def convert(x):\n",
        "    return tf.reshape(x, [8000, 1])\n",
        "\n",
        "kwargs = dict(deterministic=False, num_parallel_calls=6)\n",
        "train_dataset = tf.data.Dataset.zip((x_train.map(augment_convert), y_train)).batch(512).prefetch(100)\n",
        "valid_dataset = tf.data.Dataset.zip((x_test.map(convert), y_test)).batch(512).prefetch(100)\n",
        "next(iter(train_dataset))[0].shape, next(iter(train_dataset))[1].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([512, 8000, 1]), TensorShape([512, 12]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewv8h9DxQKSK",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK9Si5zfQmMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "lr = 0.001\n",
        "batch_size = 1024\n",
        "dropout_rate = 0.5\n",
        "input_shape = (8000,1)\n",
        "best_model_path = '.best_val_model.hdf5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqUXqv892gws",
        "colab_type": "code",
        "outputId": "fa640254-d28d-43a4-bc95-83f70eb5a2e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "# class weights\n",
        "label_cnt = Counter(labels)\n",
        "label_cnt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'down': 2152,\n",
              "         'go': 2101,\n",
              "         'left': 2165,\n",
              "         'no': 2098,\n",
              "         'off': 2143,\n",
              "         'on': 2105,\n",
              "         'right': 2155,\n",
              "         'silence': 41112,\n",
              "         'stop': 2174,\n",
              "         'unknown': 41115,\n",
              "         'up': 2062,\n",
              "         'yes': 2157})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAUB1tD73JRa",
        "colab_type": "code",
        "outputId": "07378a2a-3fc4-461c-bba3-36f5528dd8cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "label_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'down': 0,\n",
              " 'go': 1,\n",
              " 'left': 2,\n",
              " 'no': 3,\n",
              " 'off': 4,\n",
              " 'on': 5,\n",
              " 'right': 6,\n",
              " 'silence': 7,\n",
              " 'stop': 8,\n",
              " 'unknown': 9,\n",
              " 'up': 10,\n",
              " 'yes': 11}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t2yDeZx2zkn",
        "colab_type": "code",
        "outputId": "d0977307-f1a7-47f1-fc7d-24d09fb7c0fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "num_to_label = {value: key for key, value in label_dict.items()}\n",
        "class_weight = {label_dict[key]: 2062 / value for key, value in label_cnt.items()}\n",
        "class_weight"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.95817843866171,\n",
              " 1: 0.9814374107567825,\n",
              " 2: 0.9524249422632795,\n",
              " 3: 0.982840800762631,\n",
              " 4: 0.9622025198320112,\n",
              " 5: 0.9795724465558194,\n",
              " 6: 0.9568445475638051,\n",
              " 7: 0.050155672309787895,\n",
              " 8: 0.9484820607175714,\n",
              " 9: 0.05015201264745227,\n",
              " 10: 1.0,\n",
              " 11: 0.9559573481687529}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2YdfmUDEwqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = keras.models.load_model(os.path.join(data_path, \"model-089-0.875049.h5\"))\n",
        "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "#              optimizer=keras.optimizers.Adam(lr = lr),\n",
        "#              metrics=['accuracy'])\n",
        "\n",
        "#Conv1D Model\n",
        "input_tensor = Input(shape=(input_shape))\n",
        "\n",
        "x = layers.Conv1D(8, 11, padding='valid', activation='relu', strides=1)(input_tensor)\n",
        "x = layers.MaxPooling1D(2)(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.Conv1D(16, 7, padding='valid', activation='relu', strides=1)(x)\n",
        "x = layers.MaxPooling1D(2)(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.Conv1D(32, 5, padding='valid', activation='relu', strides=1)(x)\n",
        "x = layers.MaxPooling1D(10)(x)\n",
        "x = layers.LSTM(64, return_sequences=True)(x)\n",
        "x = layers.LSTM(32, return_sequences=True)(x)\n",
        "x = layers.Flatten()(x)\n",
        "# x = layers.Dense(256, activation='relu')(x)\n",
        "# x = layers.Dropout(drop_out_rate)(x)\n",
        "# x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "output_tensor = layers.Dense(12, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(input_tensor, output_tensor)\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "             optimizer=keras.optimizers.Adam(lr=lr),\n",
        "             metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePAzBl-NuHn3",
        "colab_type": "code",
        "outputId": "07b854fb-fd9c-4eea-fb0d-5680786a6e05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "mcp_save = ModelCheckpoint(best_model_path, save_best_only=True, monitor='val_loss', mode='min')\n",
        "history = model.fit(train_dataset, validation_data=valid_dataset, class_weight=class_weight, shuffle=True, epochs=500, verbose=1, callbacks=[mcp_save])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "162/162 [==============================] - 17s 107ms/step - loss: 0.5537 - accuracy: 0.3759 - val_loss: 1.7815 - val_accuracy: 0.3741\n",
            "Epoch 2/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.4902 - accuracy: 0.4264 - val_loss: 1.5982 - val_accuracy: 0.4272\n",
            "Epoch 3/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.4315 - accuracy: 0.4563 - val_loss: 1.4403 - val_accuracy: 0.4293\n",
            "Epoch 4/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.3862 - accuracy: 0.4796 - val_loss: 1.2640 - val_accuracy: 0.5300\n",
            "Epoch 5/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.3400 - accuracy: 0.5114 - val_loss: 1.3448 - val_accuracy: 0.4954\n",
            "Epoch 6/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.3036 - accuracy: 0.5442 - val_loss: 1.0941 - val_accuracy: 0.5864\n",
            "Epoch 7/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.2808 - accuracy: 0.5639 - val_loss: 0.9732 - val_accuracy: 0.6242\n",
            "Epoch 8/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.2599 - accuracy: 0.5894 - val_loss: 1.1171 - val_accuracy: 0.5762\n",
            "Epoch 9/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.2448 - accuracy: 0.6027 - val_loss: 0.9854 - val_accuracy: 0.6370\n",
            "Epoch 10/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.2308 - accuracy: 0.6229 - val_loss: 0.9044 - val_accuracy: 0.6759\n",
            "Epoch 11/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.2260 - accuracy: 0.6388 - val_loss: 0.9333 - val_accuracy: 0.6728\n",
            "Epoch 12/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.2139 - accuracy: 0.6507 - val_loss: 0.8285 - val_accuracy: 0.7067\n",
            "Epoch 13/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.2086 - accuracy: 0.6576 - val_loss: 0.8118 - val_accuracy: 0.7202\n",
            "Epoch 14/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.1974 - accuracy: 0.6737 - val_loss: 0.7990 - val_accuracy: 0.7279\n",
            "Epoch 15/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.1906 - accuracy: 0.6798 - val_loss: 0.8622 - val_accuracy: 0.7056\n",
            "Epoch 16/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.1837 - accuracy: 0.6950 - val_loss: 0.8876 - val_accuracy: 0.7037\n",
            "Epoch 17/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.1783 - accuracy: 0.7051 - val_loss: 0.8095 - val_accuracy: 0.7275\n",
            "Epoch 18/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.1681 - accuracy: 0.7171 - val_loss: 0.8980 - val_accuracy: 0.6836\n",
            "Epoch 19/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1680 - accuracy: 0.7207 - val_loss: 0.7722 - val_accuracy: 0.7444\n",
            "Epoch 20/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1631 - accuracy: 0.7235 - val_loss: 0.8080 - val_accuracy: 0.7461\n",
            "Epoch 21/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.1581 - accuracy: 0.7394 - val_loss: 0.7837 - val_accuracy: 0.7466\n",
            "Epoch 22/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1547 - accuracy: 0.7432 - val_loss: 0.7704 - val_accuracy: 0.7509\n",
            "Epoch 23/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1489 - accuracy: 0.7485 - val_loss: 0.8167 - val_accuracy: 0.7462\n",
            "Epoch 24/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1480 - accuracy: 0.7495 - val_loss: 0.7997 - val_accuracy: 0.7566\n",
            "Epoch 25/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1437 - accuracy: 0.7567 - val_loss: 0.7596 - val_accuracy: 0.7538\n",
            "Epoch 26/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.1407 - accuracy: 0.7611 - val_loss: 0.7973 - val_accuracy: 0.7364\n",
            "Epoch 27/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1377 - accuracy: 0.7649 - val_loss: 0.7495 - val_accuracy: 0.7516\n",
            "Epoch 28/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1341 - accuracy: 0.7677 - val_loss: 0.8083 - val_accuracy: 0.7416\n",
            "Epoch 29/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1328 - accuracy: 0.7723 - val_loss: 0.7605 - val_accuracy: 0.7340\n",
            "Epoch 30/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.1302 - accuracy: 0.7735 - val_loss: 0.9059 - val_accuracy: 0.7189\n",
            "Epoch 31/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1240 - accuracy: 0.7845 - val_loss: 0.6909 - val_accuracy: 0.7884\n",
            "Epoch 32/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1266 - accuracy: 0.7780 - val_loss: 0.6737 - val_accuracy: 0.7794\n",
            "Epoch 33/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1223 - accuracy: 0.7852 - val_loss: 0.6827 - val_accuracy: 0.7934\n",
            "Epoch 34/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1222 - accuracy: 0.7855 - val_loss: 0.6579 - val_accuracy: 0.8014\n",
            "Epoch 35/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.1206 - accuracy: 0.7918 - val_loss: 0.7617 - val_accuracy: 0.7310\n",
            "Epoch 36/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1169 - accuracy: 0.7943 - val_loss: 0.6335 - val_accuracy: 0.8026\n",
            "Epoch 37/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1138 - accuracy: 0.7966 - val_loss: 0.6629 - val_accuracy: 0.7918\n",
            "Epoch 38/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1149 - accuracy: 0.7984 - val_loss: 0.7153 - val_accuracy: 0.7809\n",
            "Epoch 39/500\n",
            "162/162 [==============================] - 17s 105ms/step - loss: 0.1145 - accuracy: 0.7986 - val_loss: 0.6208 - val_accuracy: 0.8023\n",
            "Epoch 40/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1125 - accuracy: 0.8023 - val_loss: 0.7027 - val_accuracy: 0.7510\n",
            "Epoch 41/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1080 - accuracy: 0.8055 - val_loss: 0.7107 - val_accuracy: 0.7477\n",
            "Epoch 42/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1092 - accuracy: 0.8093 - val_loss: 0.5607 - val_accuracy: 0.8215\n",
            "Epoch 43/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.1049 - accuracy: 0.8125 - val_loss: 0.6312 - val_accuracy: 0.8043\n",
            "Epoch 44/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.1046 - accuracy: 0.8193 - val_loss: 0.6481 - val_accuracy: 0.7942\n",
            "Epoch 45/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.1038 - accuracy: 0.8148 - val_loss: 0.6854 - val_accuracy: 0.7660\n",
            "Epoch 46/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.1033 - accuracy: 0.8112 - val_loss: 0.6617 - val_accuracy: 0.7861\n",
            "Epoch 47/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.1017 - accuracy: 0.8160 - val_loss: 0.5670 - val_accuracy: 0.8197\n",
            "Epoch 48/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0990 - accuracy: 0.8223 - val_loss: 0.6523 - val_accuracy: 0.7896\n",
            "Epoch 49/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.1030 - accuracy: 0.8209 - val_loss: 0.6021 - val_accuracy: 0.8098\n",
            "Epoch 50/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0984 - accuracy: 0.8227 - val_loss: 0.5839 - val_accuracy: 0.8214\n",
            "Epoch 51/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0947 - accuracy: 0.8332 - val_loss: 0.5700 - val_accuracy: 0.8262\n",
            "Epoch 52/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0940 - accuracy: 0.8316 - val_loss: 0.6266 - val_accuracy: 0.8143\n",
            "Epoch 53/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0957 - accuracy: 0.8289 - val_loss: 0.5371 - val_accuracy: 0.8326\n",
            "Epoch 54/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0954 - accuracy: 0.8300 - val_loss: 0.6600 - val_accuracy: 0.7773\n",
            "Epoch 55/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0925 - accuracy: 0.8348 - val_loss: 0.7614 - val_accuracy: 0.7654\n",
            "Epoch 56/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0935 - accuracy: 0.8313 - val_loss: 0.6336 - val_accuracy: 0.7892\n",
            "Epoch 57/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0895 - accuracy: 0.8367 - val_loss: 0.6021 - val_accuracy: 0.8015\n",
            "Epoch 58/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0902 - accuracy: 0.8411 - val_loss: 0.5795 - val_accuracy: 0.8202\n",
            "Epoch 59/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0883 - accuracy: 0.8419 - val_loss: 0.6892 - val_accuracy: 0.7780\n",
            "Epoch 60/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0862 - accuracy: 0.8449 - val_loss: 0.5462 - val_accuracy: 0.8316\n",
            "Epoch 61/500\n",
            "162/162 [==============================] - 17s 102ms/step - loss: 0.0898 - accuracy: 0.8422 - val_loss: 0.5554 - val_accuracy: 0.8331\n",
            "Epoch 62/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0885 - accuracy: 0.8421 - val_loss: 0.5855 - val_accuracy: 0.8309\n",
            "Epoch 63/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0858 - accuracy: 0.8483 - val_loss: 0.6180 - val_accuracy: 0.8174\n",
            "Epoch 64/500\n",
            "162/162 [==============================] - 17s 102ms/step - loss: 0.0859 - accuracy: 0.8432 - val_loss: 0.6081 - val_accuracy: 0.8260\n",
            "Epoch 65/500\n",
            "162/162 [==============================] - 17s 102ms/step - loss: 0.0831 - accuracy: 0.8465 - val_loss: 0.5635 - val_accuracy: 0.8269\n",
            "Epoch 66/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0819 - accuracy: 0.8498 - val_loss: 0.5744 - val_accuracy: 0.8298\n",
            "Epoch 67/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0852 - accuracy: 0.8483 - val_loss: 0.5147 - val_accuracy: 0.8562\n",
            "Epoch 68/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0829 - accuracy: 0.8506 - val_loss: 0.7628 - val_accuracy: 0.7847\n",
            "Epoch 69/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0824 - accuracy: 0.8512 - val_loss: 0.6997 - val_accuracy: 0.7861\n",
            "Epoch 70/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0785 - accuracy: 0.8552 - val_loss: 0.6597 - val_accuracy: 0.7926\n",
            "Epoch 71/500\n",
            "162/162 [==============================] - 17s 102ms/step - loss: 0.0799 - accuracy: 0.8545 - val_loss: 0.6175 - val_accuracy: 0.8019\n",
            "Epoch 72/500\n",
            "162/162 [==============================] - 17s 102ms/step - loss: 0.0780 - accuracy: 0.8598 - val_loss: 0.6046 - val_accuracy: 0.8111\n",
            "Epoch 73/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0823 - accuracy: 0.8543 - val_loss: 0.5203 - val_accuracy: 0.8536\n",
            "Epoch 74/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0773 - accuracy: 0.8590 - val_loss: 0.5237 - val_accuracy: 0.8279\n",
            "Epoch 75/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0765 - accuracy: 0.8631 - val_loss: 0.5444 - val_accuracy: 0.8398\n",
            "Epoch 76/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0739 - accuracy: 0.8650 - val_loss: 0.5128 - val_accuracy: 0.8575\n",
            "Epoch 77/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0757 - accuracy: 0.8623 - val_loss: 0.6549 - val_accuracy: 0.7892\n",
            "Epoch 78/500\n",
            "162/162 [==============================] - 17s 102ms/step - loss: 0.0786 - accuracy: 0.8581 - val_loss: 0.5709 - val_accuracy: 0.8325\n",
            "Epoch 79/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0732 - accuracy: 0.8637 - val_loss: 0.5418 - val_accuracy: 0.8501\n",
            "Epoch 80/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0770 - accuracy: 0.8648 - val_loss: 0.6741 - val_accuracy: 0.7956\n",
            "Epoch 81/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0713 - accuracy: 0.8681 - val_loss: 0.5661 - val_accuracy: 0.8430\n",
            "Epoch 82/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0736 - accuracy: 0.8661 - val_loss: 0.5408 - val_accuracy: 0.8433\n",
            "Epoch 83/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0734 - accuracy: 0.8650 - val_loss: 0.4999 - val_accuracy: 0.8606\n",
            "Epoch 84/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0740 - accuracy: 0.8681 - val_loss: 0.5257 - val_accuracy: 0.8527\n",
            "Epoch 85/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0711 - accuracy: 0.8720 - val_loss: 0.5103 - val_accuracy: 0.8555\n",
            "Epoch 86/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0709 - accuracy: 0.8685 - val_loss: 0.5357 - val_accuracy: 0.8452\n",
            "Epoch 87/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0714 - accuracy: 0.8699 - val_loss: 0.5271 - val_accuracy: 0.8423\n",
            "Epoch 88/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0717 - accuracy: 0.8659 - val_loss: 0.5595 - val_accuracy: 0.8420\n",
            "Epoch 89/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0701 - accuracy: 0.8711 - val_loss: 0.5919 - val_accuracy: 0.8347\n",
            "Epoch 90/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0709 - accuracy: 0.8711 - val_loss: 0.5329 - val_accuracy: 0.8489\n",
            "Epoch 91/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0764 - accuracy: 0.8659 - val_loss: 0.6282 - val_accuracy: 0.8022\n",
            "Epoch 92/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0704 - accuracy: 0.8706 - val_loss: 0.4445 - val_accuracy: 0.8774\n",
            "Epoch 93/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0665 - accuracy: 0.8784 - val_loss: 0.6556 - val_accuracy: 0.7900\n",
            "Epoch 94/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0693 - accuracy: 0.8743 - val_loss: 0.5606 - val_accuracy: 0.8202\n",
            "Epoch 95/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0671 - accuracy: 0.8764 - val_loss: 0.4595 - val_accuracy: 0.8743\n",
            "Epoch 96/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0725 - accuracy: 0.8741 - val_loss: 0.5333 - val_accuracy: 0.8521\n",
            "Epoch 97/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0676 - accuracy: 0.8749 - val_loss: 0.4492 - val_accuracy: 0.8713\n",
            "Epoch 98/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0678 - accuracy: 0.8762 - val_loss: 0.5857 - val_accuracy: 0.8169\n",
            "Epoch 99/500\n",
            "162/162 [==============================] - 17s 102ms/step - loss: 0.0639 - accuracy: 0.8780 - val_loss: 0.4916 - val_accuracy: 0.8622\n",
            "Epoch 100/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0618 - accuracy: 0.8838 - val_loss: 0.5372 - val_accuracy: 0.8276\n",
            "Epoch 101/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0682 - accuracy: 0.8816 - val_loss: 0.5575 - val_accuracy: 0.8356\n",
            "Epoch 102/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0660 - accuracy: 0.8764 - val_loss: 0.4477 - val_accuracy: 0.8780\n",
            "Epoch 103/500\n",
            "162/162 [==============================] - 17s 102ms/step - loss: 0.0661 - accuracy: 0.8827 - val_loss: 0.5116 - val_accuracy: 0.8561\n",
            "Epoch 104/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0642 - accuracy: 0.8794 - val_loss: 0.5126 - val_accuracy: 0.8629\n",
            "Epoch 105/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0645 - accuracy: 0.8805 - val_loss: 0.5219 - val_accuracy: 0.8551\n",
            "Epoch 106/500\n",
            "162/162 [==============================] - 17s 102ms/step - loss: 0.0637 - accuracy: 0.8849 - val_loss: 0.5440 - val_accuracy: 0.8598\n",
            "Epoch 107/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0616 - accuracy: 0.8843 - val_loss: 0.5943 - val_accuracy: 0.8167\n",
            "Epoch 108/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0663 - accuracy: 0.8778 - val_loss: 0.5019 - val_accuracy: 0.8629\n",
            "Epoch 109/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0628 - accuracy: 0.8877 - val_loss: 0.6502 - val_accuracy: 0.8063\n",
            "Epoch 110/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0608 - accuracy: 0.8862 - val_loss: 0.4593 - val_accuracy: 0.8820\n",
            "Epoch 111/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0644 - accuracy: 0.8868 - val_loss: 0.6019 - val_accuracy: 0.8106\n",
            "Epoch 112/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0610 - accuracy: 0.8903 - val_loss: 0.6435 - val_accuracy: 0.8028\n",
            "Epoch 113/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0613 - accuracy: 0.8846 - val_loss: 0.5628 - val_accuracy: 0.8225\n",
            "Epoch 114/500\n",
            "162/162 [==============================] - 17s 102ms/step - loss: 0.0623 - accuracy: 0.8894 - val_loss: 0.6276 - val_accuracy: 0.8015\n",
            "Epoch 115/500\n",
            "162/162 [==============================] - 17s 102ms/step - loss: 0.0578 - accuracy: 0.8919 - val_loss: 0.4647 - val_accuracy: 0.8755\n",
            "Epoch 116/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0619 - accuracy: 0.8870 - val_loss: 0.5755 - val_accuracy: 0.8414\n",
            "Epoch 117/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0589 - accuracy: 0.8929 - val_loss: 0.4551 - val_accuracy: 0.8788\n",
            "Epoch 118/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0587 - accuracy: 0.8903 - val_loss: 0.6119 - val_accuracy: 0.8144\n",
            "Epoch 119/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0625 - accuracy: 0.8871 - val_loss: 0.5048 - val_accuracy: 0.8638\n",
            "Epoch 120/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0608 - accuracy: 0.8888 - val_loss: 0.5539 - val_accuracy: 0.8222\n",
            "Epoch 121/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0606 - accuracy: 0.8898 - val_loss: 0.5985 - val_accuracy: 0.7939\n",
            "Epoch 122/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0594 - accuracy: 0.8907 - val_loss: 0.6299 - val_accuracy: 0.8395\n",
            "Epoch 123/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0569 - accuracy: 0.8973 - val_loss: 0.6028 - val_accuracy: 0.8292\n",
            "Epoch 124/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0594 - accuracy: 0.8913 - val_loss: 0.5531 - val_accuracy: 0.8649\n",
            "Epoch 125/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0592 - accuracy: 0.8901 - val_loss: 0.5473 - val_accuracy: 0.8268\n",
            "Epoch 126/500\n",
            "162/162 [==============================] - 17s 102ms/step - loss: 0.0558 - accuracy: 0.8964 - val_loss: 0.6118 - val_accuracy: 0.8148\n",
            "Epoch 127/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0591 - accuracy: 0.8913 - val_loss: 0.5794 - val_accuracy: 0.8407\n",
            "Epoch 128/500\n",
            "162/162 [==============================] - 17s 102ms/step - loss: 0.0598 - accuracy: 0.8922 - val_loss: 0.5712 - val_accuracy: 0.8523\n",
            "Epoch 129/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0558 - accuracy: 0.8932 - val_loss: 0.5425 - val_accuracy: 0.8647\n",
            "Epoch 130/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0566 - accuracy: 0.8980 - val_loss: 0.6673 - val_accuracy: 0.8067\n",
            "Epoch 131/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0552 - accuracy: 0.8972 - val_loss: 0.5574 - val_accuracy: 0.8594\n",
            "Epoch 132/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0531 - accuracy: 0.9010 - val_loss: 0.4775 - val_accuracy: 0.8780\n",
            "Epoch 133/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0531 - accuracy: 0.9011 - val_loss: 0.7384 - val_accuracy: 0.7745\n",
            "Epoch 134/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0551 - accuracy: 0.8987 - val_loss: 0.6319 - val_accuracy: 0.8028\n",
            "Epoch 135/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0566 - accuracy: 0.8969 - val_loss: 0.5063 - val_accuracy: 0.8729\n",
            "Epoch 136/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0541 - accuracy: 0.8993 - val_loss: 0.5634 - val_accuracy: 0.8380\n",
            "Epoch 137/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0517 - accuracy: 0.9036 - val_loss: 0.6831 - val_accuracy: 0.8169\n",
            "Epoch 138/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0558 - accuracy: 0.8991 - val_loss: 0.6541 - val_accuracy: 0.7924\n",
            "Epoch 139/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0567 - accuracy: 0.8982 - val_loss: 0.4915 - val_accuracy: 0.8772\n",
            "Epoch 140/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0529 - accuracy: 0.9032 - val_loss: 0.7389 - val_accuracy: 0.8120\n",
            "Epoch 141/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0564 - accuracy: 0.8943 - val_loss: 0.5954 - val_accuracy: 0.8130\n",
            "Epoch 142/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0507 - accuracy: 0.9009 - val_loss: 0.5341 - val_accuracy: 0.8398\n",
            "Epoch 143/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0560 - accuracy: 0.8995 - val_loss: 0.4924 - val_accuracy: 0.8662\n",
            "Epoch 144/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0556 - accuracy: 0.9014 - val_loss: 0.5408 - val_accuracy: 0.8512\n",
            "Epoch 145/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0553 - accuracy: 0.8995 - val_loss: 0.6069 - val_accuracy: 0.8332\n",
            "Epoch 146/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0510 - accuracy: 0.9014 - val_loss: 0.5564 - val_accuracy: 0.8455\n",
            "Epoch 147/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0503 - accuracy: 0.9050 - val_loss: 0.4623 - val_accuracy: 0.8863\n",
            "Epoch 148/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0502 - accuracy: 0.9070 - val_loss: 0.5062 - val_accuracy: 0.8480\n",
            "Epoch 149/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0507 - accuracy: 0.9032 - val_loss: 0.5434 - val_accuracy: 0.8322\n",
            "Epoch 150/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0507 - accuracy: 0.9045 - val_loss: 0.5689 - val_accuracy: 0.8191\n",
            "Epoch 151/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0551 - accuracy: 0.8982 - val_loss: 0.5256 - val_accuracy: 0.8383\n",
            "Epoch 152/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0554 - accuracy: 0.8958 - val_loss: 0.5953 - val_accuracy: 0.8360\n",
            "Epoch 153/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0488 - accuracy: 0.9062 - val_loss: 0.6568 - val_accuracy: 0.8274\n",
            "Epoch 154/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0504 - accuracy: 0.9072 - val_loss: 0.4995 - val_accuracy: 0.8687\n",
            "Epoch 155/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0544 - accuracy: 0.9048 - val_loss: 0.5390 - val_accuracy: 0.8420\n",
            "Epoch 156/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0497 - accuracy: 0.9050 - val_loss: 0.5025 - val_accuracy: 0.8799\n",
            "Epoch 157/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0495 - accuracy: 0.9064 - val_loss: 0.5199 - val_accuracy: 0.8471\n",
            "Epoch 158/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0498 - accuracy: 0.9028 - val_loss: 0.5602 - val_accuracy: 0.8592\n",
            "Epoch 159/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0504 - accuracy: 0.9041 - val_loss: 0.5191 - val_accuracy: 0.8733\n",
            "Epoch 160/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0497 - accuracy: 0.9074 - val_loss: 0.6521 - val_accuracy: 0.8320\n",
            "Epoch 161/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0501 - accuracy: 0.9062 - val_loss: 0.7538 - val_accuracy: 0.7818\n",
            "Epoch 162/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0488 - accuracy: 0.9114 - val_loss: 0.4159 - val_accuracy: 0.8985\n",
            "Epoch 163/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0481 - accuracy: 0.9104 - val_loss: 0.4083 - val_accuracy: 0.8990\n",
            "Epoch 164/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0481 - accuracy: 0.9114 - val_loss: 0.5521 - val_accuracy: 0.8399\n",
            "Epoch 165/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0519 - accuracy: 0.9055 - val_loss: 0.6046 - val_accuracy: 0.8327\n",
            "Epoch 166/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0487 - accuracy: 0.9097 - val_loss: 0.6575 - val_accuracy: 0.8063\n",
            "Epoch 167/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0498 - accuracy: 0.9092 - val_loss: 0.7241 - val_accuracy: 0.8172\n",
            "Epoch 168/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0477 - accuracy: 0.9117 - val_loss: 0.6609 - val_accuracy: 0.8236\n",
            "Epoch 169/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0485 - accuracy: 0.9124 - val_loss: 0.5708 - val_accuracy: 0.8657\n",
            "Epoch 170/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0459 - accuracy: 0.9119 - val_loss: 0.5471 - val_accuracy: 0.8652\n",
            "Epoch 171/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0457 - accuracy: 0.9167 - val_loss: 0.6253 - val_accuracy: 0.8194\n",
            "Epoch 172/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0486 - accuracy: 0.9100 - val_loss: 0.5308 - val_accuracy: 0.8447\n",
            "Epoch 173/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0478 - accuracy: 0.9125 - val_loss: 0.6355 - val_accuracy: 0.8131\n",
            "Epoch 174/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0473 - accuracy: 0.9130 - val_loss: 0.6577 - val_accuracy: 0.7966\n",
            "Epoch 175/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0492 - accuracy: 0.9057 - val_loss: 0.6466 - val_accuracy: 0.8032\n",
            "Epoch 176/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0478 - accuracy: 0.9116 - val_loss: 0.5604 - val_accuracy: 0.8327\n",
            "Epoch 177/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0479 - accuracy: 0.9111 - val_loss: 0.6191 - val_accuracy: 0.8225\n",
            "Epoch 178/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0474 - accuracy: 0.9111 - val_loss: 0.4989 - val_accuracy: 0.8523\n",
            "Epoch 179/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0467 - accuracy: 0.9116 - val_loss: 0.5886 - val_accuracy: 0.8277\n",
            "Epoch 180/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0491 - accuracy: 0.9110 - val_loss: 0.6741 - val_accuracy: 0.8043\n",
            "Epoch 181/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0478 - accuracy: 0.9137 - val_loss: 0.5006 - val_accuracy: 0.8780\n",
            "Epoch 182/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0463 - accuracy: 0.9151 - val_loss: 0.5675 - val_accuracy: 0.8331\n",
            "Epoch 183/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0472 - accuracy: 0.9125 - val_loss: 0.6216 - val_accuracy: 0.8390\n",
            "Epoch 184/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0481 - accuracy: 0.9095 - val_loss: 0.5203 - val_accuracy: 0.8501\n",
            "Epoch 185/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0470 - accuracy: 0.9131 - val_loss: 0.6421 - val_accuracy: 0.8217\n",
            "Epoch 186/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0461 - accuracy: 0.9140 - val_loss: 0.4767 - val_accuracy: 0.8807\n",
            "Epoch 187/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0473 - accuracy: 0.9122 - val_loss: 0.7016 - val_accuracy: 0.7952\n",
            "Epoch 188/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0457 - accuracy: 0.9146 - val_loss: 0.5765 - val_accuracy: 0.8143\n",
            "Epoch 189/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0427 - accuracy: 0.9186 - val_loss: 0.5726 - val_accuracy: 0.8343\n",
            "Epoch 190/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0438 - accuracy: 0.9150 - val_loss: 0.5475 - val_accuracy: 0.8669\n",
            "Epoch 191/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0449 - accuracy: 0.9177 - val_loss: 0.5618 - val_accuracy: 0.8368\n",
            "Epoch 192/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0469 - accuracy: 0.9127 - val_loss: 0.5210 - val_accuracy: 0.8752\n",
            "Epoch 193/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0442 - accuracy: 0.9143 - val_loss: 0.5940 - val_accuracy: 0.8329\n",
            "Epoch 194/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0437 - accuracy: 0.9189 - val_loss: 0.5721 - val_accuracy: 0.8540\n",
            "Epoch 195/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0442 - accuracy: 0.9179 - val_loss: 0.5985 - val_accuracy: 0.8393\n",
            "Epoch 196/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0424 - accuracy: 0.9176 - val_loss: 1.0145 - val_accuracy: 0.8053\n",
            "Epoch 197/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0425 - accuracy: 0.9195 - val_loss: 0.4743 - val_accuracy: 0.8913\n",
            "Epoch 198/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0480 - accuracy: 0.9127 - val_loss: 0.6626 - val_accuracy: 0.8146\n",
            "Epoch 199/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0442 - accuracy: 0.9134 - val_loss: 0.5020 - val_accuracy: 0.8797\n",
            "Epoch 200/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0450 - accuracy: 0.9170 - val_loss: 0.6022 - val_accuracy: 0.8368\n",
            "Epoch 201/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0450 - accuracy: 0.9136 - val_loss: 0.6795 - val_accuracy: 0.8097\n",
            "Epoch 202/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0415 - accuracy: 0.9231 - val_loss: 0.7445 - val_accuracy: 0.7797\n",
            "Epoch 203/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0418 - accuracy: 0.9218 - val_loss: 0.6176 - val_accuracy: 0.8241\n",
            "Epoch 204/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0420 - accuracy: 0.9207 - val_loss: 0.5507 - val_accuracy: 0.8418\n",
            "Epoch 205/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0442 - accuracy: 0.9173 - val_loss: 0.4816 - val_accuracy: 0.8837\n",
            "Epoch 206/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0443 - accuracy: 0.9191 - val_loss: 0.4879 - val_accuracy: 0.8637\n",
            "Epoch 207/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0395 - accuracy: 0.9209 - val_loss: 0.5558 - val_accuracy: 0.8389\n",
            "Epoch 208/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0430 - accuracy: 0.9188 - val_loss: 0.6447 - val_accuracy: 0.8107\n",
            "Epoch 209/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0450 - accuracy: 0.9167 - val_loss: 0.6540 - val_accuracy: 0.8079\n",
            "Epoch 210/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0414 - accuracy: 0.9215 - val_loss: 0.4773 - val_accuracy: 0.8554\n",
            "Epoch 211/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0417 - accuracy: 0.9227 - val_loss: 0.5073 - val_accuracy: 0.8825\n",
            "Epoch 212/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0418 - accuracy: 0.9237 - val_loss: 0.4730 - val_accuracy: 0.9002\n",
            "Epoch 213/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0431 - accuracy: 0.9205 - val_loss: 0.8323 - val_accuracy: 0.7696\n",
            "Epoch 214/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0433 - accuracy: 0.9206 - val_loss: 0.7109 - val_accuracy: 0.8136\n",
            "Epoch 215/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0425 - accuracy: 0.9196 - val_loss: 0.5020 - val_accuracy: 0.8852\n",
            "Epoch 216/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0411 - accuracy: 0.9217 - val_loss: 0.5107 - val_accuracy: 0.8704\n",
            "Epoch 217/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0452 - accuracy: 0.9191 - val_loss: 0.5453 - val_accuracy: 0.8644\n",
            "Epoch 218/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0430 - accuracy: 0.9230 - val_loss: 0.7805 - val_accuracy: 0.8176\n",
            "Epoch 219/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0439 - accuracy: 0.9173 - val_loss: 0.6303 - val_accuracy: 0.8383\n",
            "Epoch 220/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0400 - accuracy: 0.9229 - val_loss: 0.6908 - val_accuracy: 0.8363\n",
            "Epoch 221/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0449 - accuracy: 0.9211 - val_loss: 0.5796 - val_accuracy: 0.8543\n",
            "Epoch 222/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0452 - accuracy: 0.9168 - val_loss: 0.5465 - val_accuracy: 0.8467\n",
            "Epoch 223/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0380 - accuracy: 0.9258 - val_loss: 0.4863 - val_accuracy: 0.8910\n",
            "Epoch 224/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0428 - accuracy: 0.9251 - val_loss: 0.5586 - val_accuracy: 0.8376\n",
            "Epoch 225/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0384 - accuracy: 0.9273 - val_loss: 0.4988 - val_accuracy: 0.8908\n",
            "Epoch 226/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0400 - accuracy: 0.9239 - val_loss: 0.6493 - val_accuracy: 0.8215\n",
            "Epoch 227/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0405 - accuracy: 0.9252 - val_loss: 0.7124 - val_accuracy: 0.8124\n",
            "Epoch 228/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0409 - accuracy: 0.9248 - val_loss: 0.8371 - val_accuracy: 0.7827\n",
            "Epoch 229/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0397 - accuracy: 0.9225 - val_loss: 0.4271 - val_accuracy: 0.8952\n",
            "Epoch 230/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0411 - accuracy: 0.9238 - val_loss: 0.9202 - val_accuracy: 0.7961\n",
            "Epoch 231/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0431 - accuracy: 0.9223 - val_loss: 1.0804 - val_accuracy: 0.7881\n",
            "Epoch 232/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0384 - accuracy: 0.9289 - val_loss: 0.6703 - val_accuracy: 0.8464\n",
            "Epoch 233/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0413 - accuracy: 0.9265 - val_loss: 0.6553 - val_accuracy: 0.8376\n",
            "Epoch 234/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0394 - accuracy: 0.9230 - val_loss: 0.6870 - val_accuracy: 0.8362\n",
            "Epoch 235/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0401 - accuracy: 0.9240 - val_loss: 0.6450 - val_accuracy: 0.8336\n",
            "Epoch 236/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0391 - accuracy: 0.9254 - val_loss: 0.7490 - val_accuracy: 0.8072\n",
            "Epoch 237/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0398 - accuracy: 0.9243 - val_loss: 0.5155 - val_accuracy: 0.8484\n",
            "Epoch 238/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0425 - accuracy: 0.9228 - val_loss: 0.5714 - val_accuracy: 0.8462\n",
            "Epoch 239/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0389 - accuracy: 0.9275 - val_loss: 0.5190 - val_accuracy: 0.8780\n",
            "Epoch 240/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0415 - accuracy: 0.9249 - val_loss: 0.5517 - val_accuracy: 0.8741\n",
            "Epoch 241/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0420 - accuracy: 0.9244 - val_loss: 0.7040 - val_accuracy: 0.7883\n",
            "Epoch 242/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0408 - accuracy: 0.9213 - val_loss: 1.0812 - val_accuracy: 0.8308\n",
            "Epoch 243/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0420 - accuracy: 0.9211 - val_loss: 0.8034 - val_accuracy: 0.7769\n",
            "Epoch 244/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0432 - accuracy: 0.9212 - val_loss: 0.7170 - val_accuracy: 0.8142\n",
            "Epoch 245/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0428 - accuracy: 0.9207 - val_loss: 0.6441 - val_accuracy: 0.8251\n",
            "Epoch 246/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0393 - accuracy: 0.9253 - val_loss: 0.6842 - val_accuracy: 0.8403\n",
            "Epoch 247/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0395 - accuracy: 0.9286 - val_loss: 0.7837 - val_accuracy: 0.8192\n",
            "Epoch 248/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0371 - accuracy: 0.9322 - val_loss: 0.5362 - val_accuracy: 0.8814\n",
            "Epoch 249/500\n",
            "162/162 [==============================] - 17s 102ms/step - loss: 0.0367 - accuracy: 0.9277 - val_loss: 0.7940 - val_accuracy: 0.8262\n",
            "Epoch 250/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0409 - accuracy: 0.9245 - val_loss: 0.7695 - val_accuracy: 0.8284\n",
            "Epoch 251/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0383 - accuracy: 0.9287 - val_loss: 0.7726 - val_accuracy: 0.7949\n",
            "Epoch 252/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0410 - accuracy: 0.9253 - val_loss: 0.8936 - val_accuracy: 0.8071\n",
            "Epoch 253/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0367 - accuracy: 0.9304 - val_loss: 0.6259 - val_accuracy: 0.8261\n",
            "Epoch 254/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0386 - accuracy: 0.9283 - val_loss: 0.7942 - val_accuracy: 0.8338\n",
            "Epoch 255/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0386 - accuracy: 0.9283 - val_loss: 0.6176 - val_accuracy: 0.8617\n",
            "Epoch 256/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0380 - accuracy: 0.9285 - val_loss: 0.5738 - val_accuracy: 0.8456\n",
            "Epoch 257/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0369 - accuracy: 0.9284 - val_loss: 0.7760 - val_accuracy: 0.8339\n",
            "Epoch 258/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0377 - accuracy: 0.9311 - val_loss: 0.4712 - val_accuracy: 0.8997\n",
            "Epoch 259/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0401 - accuracy: 0.9285 - val_loss: 0.8157 - val_accuracy: 0.8161\n",
            "Epoch 260/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0368 - accuracy: 0.9300 - val_loss: 0.7084 - val_accuracy: 0.8347\n",
            "Epoch 261/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0383 - accuracy: 0.9274 - val_loss: 0.6005 - val_accuracy: 0.8541\n",
            "Epoch 262/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0365 - accuracy: 0.9310 - val_loss: 0.9474 - val_accuracy: 0.7991\n",
            "Epoch 263/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0365 - accuracy: 0.9276 - val_loss: 0.7763 - val_accuracy: 0.8063\n",
            "Epoch 264/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0405 - accuracy: 0.9258 - val_loss: 0.6162 - val_accuracy: 0.8405\n",
            "Epoch 265/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0407 - accuracy: 0.9278 - val_loss: 0.5489 - val_accuracy: 0.8542\n",
            "Epoch 266/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0396 - accuracy: 0.9268 - val_loss: 0.6411 - val_accuracy: 0.8329\n",
            "Epoch 267/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0397 - accuracy: 0.9274 - val_loss: 0.7865 - val_accuracy: 0.8284\n",
            "Epoch 268/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0364 - accuracy: 0.9319 - val_loss: 0.4740 - val_accuracy: 0.8933\n",
            "Epoch 269/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0339 - accuracy: 0.9361 - val_loss: 0.6302 - val_accuracy: 0.8503\n",
            "Epoch 270/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0358 - accuracy: 0.9330 - val_loss: 0.7770 - val_accuracy: 0.7954\n",
            "Epoch 271/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0376 - accuracy: 0.9293 - val_loss: 0.6897 - val_accuracy: 0.8433\n",
            "Epoch 272/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0366 - accuracy: 0.9296 - val_loss: 1.0508 - val_accuracy: 0.8335\n",
            "Epoch 273/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0370 - accuracy: 0.9307 - val_loss: 0.6013 - val_accuracy: 0.8259\n",
            "Epoch 274/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0347 - accuracy: 0.9326 - val_loss: 0.7467 - val_accuracy: 0.7859\n",
            "Epoch 275/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0390 - accuracy: 0.9303 - val_loss: 0.7715 - val_accuracy: 0.8392\n",
            "Epoch 276/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0360 - accuracy: 0.9333 - val_loss: 0.6173 - val_accuracy: 0.8464\n",
            "Epoch 277/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0354 - accuracy: 0.9340 - val_loss: 0.8514 - val_accuracy: 0.8247\n",
            "Epoch 278/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0411 - accuracy: 0.9279 - val_loss: 0.8517 - val_accuracy: 0.8191\n",
            "Epoch 279/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0371 - accuracy: 0.9295 - val_loss: 0.6488 - val_accuracy: 0.8451\n",
            "Epoch 280/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0341 - accuracy: 0.9366 - val_loss: 0.4719 - val_accuracy: 0.9001\n",
            "Epoch 281/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0357 - accuracy: 0.9310 - val_loss: 0.8638 - val_accuracy: 0.8256\n",
            "Epoch 282/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0374 - accuracy: 0.9308 - val_loss: 0.5008 - val_accuracy: 0.8808\n",
            "Epoch 283/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0358 - accuracy: 0.9347 - val_loss: 0.9324 - val_accuracy: 0.8115\n",
            "Epoch 284/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0334 - accuracy: 0.9348 - val_loss: 1.0388 - val_accuracy: 0.8201\n",
            "Epoch 285/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0335 - accuracy: 0.9352 - val_loss: 0.5651 - val_accuracy: 0.8785\n",
            "Epoch 286/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0388 - accuracy: 0.9332 - val_loss: 1.0264 - val_accuracy: 0.8289\n",
            "Epoch 287/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0346 - accuracy: 0.9357 - val_loss: 0.8128 - val_accuracy: 0.8349\n",
            "Epoch 288/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0376 - accuracy: 0.9330 - val_loss: 0.7617 - val_accuracy: 0.8318\n",
            "Epoch 289/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0368 - accuracy: 0.9355 - val_loss: 0.5122 - val_accuracy: 0.8873\n",
            "Epoch 290/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0366 - accuracy: 0.9347 - val_loss: 0.8155 - val_accuracy: 0.8349\n",
            "Epoch 291/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0361 - accuracy: 0.9316 - val_loss: 0.4744 - val_accuracy: 0.9013\n",
            "Epoch 292/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0345 - accuracy: 0.9343 - val_loss: 0.6914 - val_accuracy: 0.8409\n",
            "Epoch 293/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0364 - accuracy: 0.9328 - val_loss: 0.5058 - val_accuracy: 0.8942\n",
            "Epoch 294/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0382 - accuracy: 0.9290 - val_loss: 0.6983 - val_accuracy: 0.8337\n",
            "Epoch 295/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0358 - accuracy: 0.9310 - val_loss: 0.7452 - val_accuracy: 0.8391\n",
            "Epoch 296/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0368 - accuracy: 0.9333 - val_loss: 0.5173 - val_accuracy: 0.8681\n",
            "Epoch 297/500\n",
            "162/162 [==============================] - 17s 102ms/step - loss: 0.0368 - accuracy: 0.9318 - val_loss: 0.5576 - val_accuracy: 0.8733\n",
            "Epoch 298/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0371 - accuracy: 0.9332 - val_loss: 0.8310 - val_accuracy: 0.8255\n",
            "Epoch 299/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0350 - accuracy: 0.9367 - val_loss: 0.9349 - val_accuracy: 0.8399\n",
            "Epoch 300/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0378 - accuracy: 0.9303 - val_loss: 0.6309 - val_accuracy: 0.8608\n",
            "Epoch 301/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0341 - accuracy: 0.9356 - val_loss: 0.9037 - val_accuracy: 0.8246\n",
            "Epoch 302/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0351 - accuracy: 0.9378 - val_loss: 0.7949 - val_accuracy: 0.8331\n",
            "Epoch 303/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0331 - accuracy: 0.9358 - val_loss: 0.6925 - val_accuracy: 0.8491\n",
            "Epoch 304/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0358 - accuracy: 0.9329 - val_loss: 0.6238 - val_accuracy: 0.8593\n",
            "Epoch 305/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0378 - accuracy: 0.9295 - val_loss: 0.7174 - val_accuracy: 0.8023\n",
            "Epoch 306/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0341 - accuracy: 0.9339 - val_loss: 0.7837 - val_accuracy: 0.8286\n",
            "Epoch 307/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0342 - accuracy: 0.9341 - val_loss: 0.9872 - val_accuracy: 0.8366\n",
            "Epoch 308/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0352 - accuracy: 0.9341 - val_loss: 1.0551 - val_accuracy: 0.7736\n",
            "Epoch 309/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0371 - accuracy: 0.9345 - val_loss: 0.7826 - val_accuracy: 0.8458\n",
            "Epoch 310/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0333 - accuracy: 0.9364 - val_loss: 1.1488 - val_accuracy: 0.8327\n",
            "Epoch 311/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0381 - accuracy: 0.9340 - val_loss: 0.7339 - val_accuracy: 0.8214\n",
            "Epoch 312/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0334 - accuracy: 0.9360 - val_loss: 0.7186 - val_accuracy: 0.8362\n",
            "Epoch 313/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0331 - accuracy: 0.9393 - val_loss: 0.7018 - val_accuracy: 0.8413\n",
            "Epoch 314/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0328 - accuracy: 0.9392 - val_loss: 0.6340 - val_accuracy: 0.8387\n",
            "Epoch 315/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0344 - accuracy: 0.9364 - val_loss: 0.4338 - val_accuracy: 0.9119\n",
            "Epoch 316/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0331 - accuracy: 0.9394 - val_loss: 0.8896 - val_accuracy: 0.7913\n",
            "Epoch 317/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0326 - accuracy: 0.9388 - val_loss: 0.7419 - val_accuracy: 0.7957\n",
            "Epoch 318/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0330 - accuracy: 0.9395 - val_loss: 0.6142 - val_accuracy: 0.8701\n",
            "Epoch 319/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0379 - accuracy: 0.9296 - val_loss: 0.4859 - val_accuracy: 0.8882\n",
            "Epoch 320/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0339 - accuracy: 0.9392 - val_loss: 0.5019 - val_accuracy: 0.8950\n",
            "Epoch 321/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0334 - accuracy: 0.9381 - val_loss: 0.5929 - val_accuracy: 0.8603\n",
            "Epoch 322/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0343 - accuracy: 0.9366 - val_loss: 0.7935 - val_accuracy: 0.8294\n",
            "Epoch 323/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0329 - accuracy: 0.9377 - val_loss: 0.6282 - val_accuracy: 0.8653\n",
            "Epoch 324/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0337 - accuracy: 0.9363 - val_loss: 0.4958 - val_accuracy: 0.8954\n",
            "Epoch 325/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0335 - accuracy: 0.9383 - val_loss: 0.6062 - val_accuracy: 0.8526\n",
            "Epoch 326/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0335 - accuracy: 0.9365 - val_loss: 1.0082 - val_accuracy: 0.8303\n",
            "Epoch 327/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0330 - accuracy: 0.9374 - val_loss: 0.7757 - val_accuracy: 0.8112\n",
            "Epoch 328/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0322 - accuracy: 0.9411 - val_loss: 1.0612 - val_accuracy: 0.7994\n",
            "Epoch 329/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0348 - accuracy: 0.9358 - val_loss: 0.5405 - val_accuracy: 0.8856\n",
            "Epoch 330/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0321 - accuracy: 0.9404 - val_loss: 0.6957 - val_accuracy: 0.8401\n",
            "Epoch 331/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0339 - accuracy: 0.9363 - val_loss: 0.7358 - val_accuracy: 0.8375\n",
            "Epoch 332/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0337 - accuracy: 0.9382 - val_loss: 0.8369 - val_accuracy: 0.7971\n",
            "Epoch 333/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0343 - accuracy: 0.9382 - val_loss: 0.7850 - val_accuracy: 0.8008\n",
            "Epoch 334/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0326 - accuracy: 0.9390 - val_loss: 0.8150 - val_accuracy: 0.8324\n",
            "Epoch 335/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0315 - accuracy: 0.9402 - val_loss: 0.5654 - val_accuracy: 0.8845\n",
            "Epoch 336/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0352 - accuracy: 0.9341 - val_loss: 0.5347 - val_accuracy: 0.8843\n",
            "Epoch 337/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0345 - accuracy: 0.9365 - val_loss: 0.6404 - val_accuracy: 0.8628\n",
            "Epoch 338/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0341 - accuracy: 0.9357 - val_loss: 0.6674 - val_accuracy: 0.8527\n",
            "Epoch 339/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0325 - accuracy: 0.9409 - val_loss: 0.9347 - val_accuracy: 0.7883\n",
            "Epoch 340/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0340 - accuracy: 0.9361 - val_loss: 0.9362 - val_accuracy: 0.8236\n",
            "Epoch 341/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0318 - accuracy: 0.9401 - val_loss: 0.7857 - val_accuracy: 0.8413\n",
            "Epoch 342/500\n",
            "162/162 [==============================] - 17s 103ms/step - loss: 0.0333 - accuracy: 0.9399 - val_loss: 0.5755 - val_accuracy: 0.8777\n",
            "Epoch 343/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0333 - accuracy: 0.9395 - val_loss: 0.6369 - val_accuracy: 0.8518\n",
            "Epoch 344/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0326 - accuracy: 0.9380 - val_loss: 0.4961 - val_accuracy: 0.8977\n",
            "Epoch 345/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0333 - accuracy: 0.9387 - val_loss: 0.6907 - val_accuracy: 0.8411\n",
            "Epoch 346/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0323 - accuracy: 0.9406 - val_loss: 0.7544 - val_accuracy: 0.8443\n",
            "Epoch 347/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0331 - accuracy: 0.9389 - val_loss: 0.8705 - val_accuracy: 0.8291\n",
            "Epoch 348/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0302 - accuracy: 0.9438 - val_loss: 0.5438 - val_accuracy: 0.8887\n",
            "Epoch 349/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0317 - accuracy: 0.9440 - val_loss: 0.9672 - val_accuracy: 0.8210\n",
            "Epoch 350/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0299 - accuracy: 0.9439 - val_loss: 0.6535 - val_accuracy: 0.8567\n",
            "Epoch 351/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0319 - accuracy: 0.9409 - val_loss: 1.1339 - val_accuracy: 0.8261\n",
            "Epoch 352/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0347 - accuracy: 0.9377 - val_loss: 0.6494 - val_accuracy: 0.8467\n",
            "Epoch 353/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0342 - accuracy: 0.9386 - val_loss: 1.0714 - val_accuracy: 0.8170\n",
            "Epoch 354/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0321 - accuracy: 0.9391 - val_loss: 0.8256 - val_accuracy: 0.8230\n",
            "Epoch 355/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0346 - accuracy: 0.9364 - val_loss: 1.0968 - val_accuracy: 0.8200\n",
            "Epoch 356/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0316 - accuracy: 0.9390 - val_loss: 0.9345 - val_accuracy: 0.8350\n",
            "Epoch 357/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0327 - accuracy: 0.9414 - val_loss: 0.5265 - val_accuracy: 0.8914\n",
            "Epoch 358/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0310 - accuracy: 0.9428 - val_loss: 0.8798 - val_accuracy: 0.8326\n",
            "Epoch 359/500\n",
            "162/162 [==============================] - 17s 104ms/step - loss: 0.0304 - accuracy: 0.9439 - val_loss: 0.7600 - val_accuracy: 0.8424\n",
            "Epoch 360/500\n",
            " 42/162 [======>.......................] - ETA: 10s - loss: 0.0273 - accuracy: 0.9521Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGFvjWub0S68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = keras.models.load_model(best_model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b6Bmzp5SxLA",
        "colab_type": "text"
      },
      "source": [
        "## Running model on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4ROrEW0iDOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dict = {'down': 0,\n",
        "            'go': 1,\n",
        "            'left': 2,\n",
        "            'no': 3,\n",
        "            'off': 4,\n",
        "            'on': 5,\n",
        "            'right': 6,\n",
        "            'silence': 7,\n",
        "            'stop': 8,\n",
        "            'unknown': 9,\n",
        "            'up': 10,\n",
        "            'yes': 11}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBFGgqvJXJNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_path = os.path.join(data_path, \"test_wav_final.npy\")\n",
        "test_all = np.load(test_path).reshape(-1, 8000, 1)  # may take a while (~3 minutes) (it's almost 5GB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOk9BfMzXyvU",
        "colab_type": "code",
        "outputId": "3af51118-4130-4829-b08b-b7b7900c88a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_all.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(158538, 8000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP0lzkyvYYDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model.predict(test_all)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfOP1WjyYebH",
        "colab_type": "code",
        "outputId": "9ca79e83-d46a-466e-96ad-ab7e309d3f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "preds.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(158538, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKFz_71mYk8q",
        "colab_type": "code",
        "outputId": "0440cb8f-ffe1-41c9-b1cb-249934a66a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "num_to_label = {value: key for key, value in label_dict.items()}\n",
        "num_to_label"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'down',\n",
              " 1: 'go',\n",
              " 2: 'left',\n",
              " 3: 'no',\n",
              " 4: 'off',\n",
              " 5: 'on',\n",
              " 6: 'right',\n",
              " 7: 'silence',\n",
              " 8: 'stop',\n",
              " 9: 'unknown',\n",
              " 10: 'up',\n",
              " 11: 'yes'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LrrfW0lYmcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_labels = [num_to_label[num] for num in preds.argmax(1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iEeRA-xZgwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_file = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))\n",
        "submission_file[\"label\"] = predicted_labels\n",
        "submission_file.to_csv(os.path.join(data_path, \"submission.csv\"), index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrZIrwUdaUc_",
        "colab_type": "code",
        "outputId": "df4a532e-89ac-4ae7-968e-56d1887930a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "pd.read_csv(os.path.join(data_path, \"submission.csv\")).head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>clip_000044442.wav</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>clip_0000adecb.wav</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>clip_0000d4322.wav</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>clip_0000fb6fe.wav</td>\n",
              "      <td>silence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>clip_0001d1559.wav</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                fname    label\n",
              "0  clip_000044442.wav       no\n",
              "1  clip_0000adecb.wav  unknown\n",
              "2  clip_0000d4322.wav       no\n",
              "3  clip_0000fb6fe.wav  silence\n",
              "4  clip_0001d1559.wav  unknown"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOUv_pm9jDJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_label_cnt = Counter(submission_file.label.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vty9x9z31S7s",
        "colab_type": "code",
        "outputId": "7d5361f8-26f5-41e8-b66a-b3637ad54071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "plt.bar(predicted_label_cnt.keys(), predicted_label_cnt.values())\n",
        "plt.xticks(rotation=45)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
              " <a list of 12 Text major ticklabel objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmdYtdEt1bif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}