{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepspeech.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8ea362f02f0947628f6cbafeb8397f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_710ddab56e624a91b4e5aa7bcc25188c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_85d3567007104861a131b6c4abc70fc6",
              "IPY_MODEL_d12421473aa64beaa9b54c19729a3d50"
            ]
          }
        },
        "710ddab56e624a91b4e5aa7bcc25188c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85d3567007104861a131b6c4abc70fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fdd2ce8092dd410eb0b5a3d8bdfe4a1d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4474444352b241a6b8bff270359d5b1e"
          }
        },
        "d12421473aa64beaa9b54c19729a3d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f2ea57788db47a69a87a9369771f8b1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20/20 [01:48&lt;00:00,  5.40s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e311a54ceb4406bb93a166be73fa94d"
          }
        },
        "fdd2ce8092dd410eb0b5a3d8bdfe4a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4474444352b241a6b8bff270359d5b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f2ea57788db47a69a87a9369771f8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e311a54ceb4406bb93a166be73fa94d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMaeGDHqdHzl",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow speech recognition challenge (Kaggle)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9M1eQyP_RQb",
        "colab_type": "code",
        "outputId": "a020c5fa-ff7f-4834-c781-096bef44f0ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from collections import Counter\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import signal\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import Input, layers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tqdm.notebook import tqdm, trange\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrnMmqcsAJEW",
        "colab_type": "code",
        "outputId": "eabf9a1e-34ca-40e6-b0d2-6fef3dc05ca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "data_path = \"drive/My Drive/Colab Notebooks/data/preprocessed\"\n",
        "os.listdir(data_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample_submission.csv',\n",
              " 'wav_all.npy',\n",
              " 'label_all.npy',\n",
              " 'unknown_wav.npy',\n",
              " 'background_wav.npy',\n",
              " 'test_wav_final.npy',\n",
              " 'model-089-0.875049.h5',\n",
              " 'submission.csv',\n",
              " 'best_val_model.hdf5',\n",
              " 'best_deepspeech.hdf5',\n",
              " 'Kopia best_val_model.hdf5',\n",
              " 'Kopia best_deepspeech.hdf5']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdeRLsS3Aaaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wav_all = np.load(os.path.join(data_path, \"wav_all.npy\"), allow_pickle=True)\n",
        "wav_all = np.array([list(arr) for arr in wav_all])\n",
        "\n",
        "label_all = np.load(os.path.join(data_path, \"label_all.npy\")).reshape(-1)\n",
        "\n",
        "unknown_wav = np.load(os.path.join(data_path, \"unknown_wav.npy\"))\n",
        "background_wav = np.load(os.path.join(data_path, \"background_wav.npy\"), allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEgnocZwA8Q7",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Generating training data\n",
        "#### Generating silence samples from background noise\n",
        "Since we have around 2131 of every label in our dataset, we will generate 2131 additional samples from background noise (and label it silence, because it doesn't contain any speech)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sKyApoLEPbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_silence_samples = 41115"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4z49YjgDoi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_noise_sample(noise_num=0):\n",
        "    \"\"\"Gets random sample from selected noise type (one out of 6)\"\"\"\n",
        "    selected_noise = background_wav[noise_num]\n",
        "    start_idx = random.randint(0, len(selected_noise)- 1 - 8000)\n",
        "    return selected_noise[start_idx:(start_idx + 8000)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldySn_SqFCai",
        "colab_type": "code",
        "outputId": "522d1f20-697a-43eb-a541-8645b45b7aaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#silence audio\n",
        "silence_wav = []\n",
        "n_samples_per_noise = n_silence_samples // len(background_wav)\n",
        "for i, _ in enumerate(background_wav):\n",
        "    for _ in range(n_samples_per_noise):\n",
        "        silence_wav.append(get_noise_sample(i))\n",
        "silence_wav = np.array(silence_wav)\n",
        "silence_label = np.array(['silence' for _ in range(n_samples_per_noise * len(background_wav))])\n",
        "silence_wav.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41112, 8000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KtadH5iFOu5",
        "colab_type": "text"
      },
      "source": [
        "#### Creating samples of unknown speech\n",
        "Samples form all other labels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebywyxujHEZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unknown_wav = np.array(random.sample(list(unknown_wav), n_silence_samples))\n",
        "unknown_label = [\"unknown\" for _ in range(n_silence_samples)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8nsEtO5JJ2w",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "#### Data Processing pipeline\n",
        "The next step would be to create data processing pipeline: sample elements from the whole dataset instead of choosing fixed set of unknown samples and also doing data aumentation (mixing with noise) when doing training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZSQlPQVCipn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.concatenate([wav_all, unknown_wav, silence_wav], 0)\n",
        "labels = np.concatenate([label_all, unknown_label, silence_label], 0)\n",
        "del(wav_all)\n",
        "del(unknown_wav)\n",
        "del(silence_wav)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXUToZx6BZ8q",
        "colab_type": "code",
        "outputId": "912ad802-f419-4975-d4be-f1242c63f440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "# Converting labels to one hot vectors\n",
        "label_values = np.unique(labels)\n",
        "label_dict = {label: value for value, label in enumerate(sorted(label_values))}\n",
        "label_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'down': 0,\n",
              " 'go': 1,\n",
              " 'left': 2,\n",
              " 'no': 3,\n",
              " 'off': 4,\n",
              " 'on': 5,\n",
              " 'right': 6,\n",
              " 'silence': 7,\n",
              " 'stop': 8,\n",
              " 'unknown': 9,\n",
              " 'up': 10,\n",
              " 'yes': 11}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAartyPsJ4r4",
        "colab_type": "code",
        "outputId": "c3315323-3f35-4f7b-ec05-10fbe78b33dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "label_all = [label_dict[label] for label in labels]\n",
        "label_all = keras.utils.to_categorical(label_all, len(label_dict)).reshape(-1, 12, 1)\n",
        "label_all.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(103539, 12, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9IlnW8DAZ-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_wav, test_wav, train_label, test_label = train_test_split(data, label_all, test_size=0.1, random_state=42, shuffle=True)\n",
        "del(data)  # saving RAM space"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjZeBt7ABYF8",
        "colab_type": "text"
      },
      "source": [
        "#### Spectogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iL-6W2kBU63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_specgram(audio, sample_rate=8000, window_size=40,\n",
        "                 step_size=10, eps=1e-10):\n",
        "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
        "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
        "\n",
        "    freqs, times, spec = signal.spectrogram(audio,\n",
        "                                    fs=sample_rate,\n",
        "                                    window='hann',\n",
        "                                    nperseg=nperseg,\n",
        "                                    noverlap=noverlap,\n",
        "                                    detrend=False)\n",
        "    logspec = np.log(spec.T.astype(np.float32) + eps)\n",
        "    return logspec.reshape(*logspec.shape, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4RujTOgHsFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_wav_spec = np.array([log_specgram(x) for x in tqdm(train_wav)])\n",
        "# test_wav_spec = np.array([log_specgram(x) for x in tqdm(test_wav)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzX4DUFeXyCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_noise_sample(noise_num=0):\n",
        "    \"\"\"Gets random sample from selected noise type (one out of 6)\"\"\"\n",
        "    selected_noise = background_wav[noise_num]\n",
        "    start_idx = random.randint(0, len(selected_noise)- 1 - 8000)\n",
        "    return selected_noise[start_idx:(start_idx + 8000)]\n",
        "\n",
        "def augment_convert(x):\n",
        "    noise_ratio = random.random()\n",
        "    num = random.randint(0, 5)\n",
        "    noise = get_noise_sample(num)\n",
        "    noised_x = x + noise_ratio * noise\n",
        "    return log_specgram(noised_x)\n",
        "    # return tf.reshape(noised_x, [8000, 1])\n",
        "\n",
        "def convert(x):\n",
        "    return log_specgram(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrW9EkBYE3k3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kwargs = dict(deterministic=False, num_parallel_calls=-1)\n",
        "\n",
        "x_train = tf.data.Dataset.from_tensor_slices(train_wav).map(lambda x: tf.py_function(func=augment_convert, inp=[x], Tout=tf.float32), **kwargs)\n",
        "y_train = tf.data.Dataset.from_tensor_slices(train_label.reshape([-1, 12]))\n",
        "\n",
        "x_test = tf.data.Dataset.from_tensor_slices(test_wav).map(lambda x: tf.py_function(func=convert, inp=[x], Tout=tf.float32), **kwargs)\n",
        "y_test = tf.data.Dataset.from_tensor_slices(test_label.reshape([-1, 12]))\n",
        "\n",
        "# next(iter(x_train)).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1JFm_4s61Hi",
        "colab_type": "code",
        "outputId": "152aff9c-072f-4e62-a830-e021e55cb65b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Defining data augmentation pipeline\n",
        "train_dataset = tf.data.Dataset.zip((x_train, y_train)).batch(512).prefetch(1000)\n",
        "valid_dataset = tf.data.Dataset.zip((x_test, y_test)).batch(512).prefetch(1000)\n",
        "next(iter(train_dataset))[0].shape, next(iter(train_dataset))[1].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([512, 33, 161, 1]), TensorShape([512, 12]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewv8h9DxQKSK",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK9Si5zfQmMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "lr = 0.001\n",
        "initial_lr = 0.001\n",
        "batch_size = 1024\n",
        "dropout_rate = 0.5\n",
        "input_shape = (99, 81, 1)\n",
        "best_model_path = '.best_val_model.hdf5'\n",
        "\n",
        "# class weights\n",
        "label_cnt = Counter(labels)\n",
        "num_to_label = {value: key for key, value in label_dict.items()}\n",
        "class_weight = {label_dict[key]: 2062 / value for key, value in label_cnt.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2-MFDZLQgSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "    if epoch < 2:\n",
        "        return 0.002\n",
        "    elif epoch < 50:\n",
        "        return 0.001\n",
        "    elif epoch < 75:\n",
        "        return 0.0001\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "schedule = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BZMokUQHMWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = (33, 161, 1)\n",
        "input_dim = input_shape[1]\n",
        "rnn_units = 512\n",
        "output_dim = 12\n",
        "\n",
        "input_tensor = Input(shape=(input_shape))\n",
        "\n",
        "x = layers.BatchNormalization(axis=2)(input_tensor)\n",
        "\n",
        "\n",
        "# Add 4th dimension [batch, time, frequency, channel]\n",
        "# x = layers.Lambda(keras.backend.expand_dims,\n",
        "#                   arguments=dict(axis=-1))(input_tensor)\n",
        "x = layers.Conv2D(filters=32,\n",
        "                    kernel_size=[11, 41],\n",
        "                    strides=[2, 2],\n",
        "                    padding='same',\n",
        "                    use_bias=False,\n",
        "                    name='conv_1')(x)\n",
        "x = layers.BatchNormalization(name='conv_1_bn')(x)\n",
        "x = layers.ReLU(name='conv_1_relu')(x)\n",
        "\n",
        "x = layers.Conv2D(filters=32,\n",
        "                    kernel_size=[11, 21],\n",
        "                    strides=[1, 2],\n",
        "                    padding='same',\n",
        "                    use_bias=False,\n",
        "                    name='conv_2')(x)\n",
        "x = layers.BatchNormalization(name='conv_2_bn')(x)\n",
        "x = layers.ReLU(name='conv_2_relu')(x)\n",
        "# We need to squeeze to 3D tensor. Thanks to the stride in frequency\n",
        "# domain, we reduce the number of features four times for each channel.\n",
        "# x = layers.Reshape([-1, input_dim//4*32])(x)\n",
        "\n",
        "x = layers.Reshape((x.shape[1], x.shape[2]*x.shape[3]))(x)\n",
        "\n",
        "# for i in [1, 2, 3, 4, 5]:\n",
        "for i in [1, 2]:\n",
        "\n",
        "    recurrent = layers.GRU(units=rnn_units,\n",
        "                            activation='tanh',\n",
        "                            recurrent_activation='sigmoid',\n",
        "                            use_bias=True,\n",
        "                            return_sequences=True,\n",
        "                            reset_after=True,\n",
        "                            name=f'gru_{i}')\n",
        "    x = layers.Bidirectional(recurrent,\n",
        "                                name=f'bidirectional_{i}',\n",
        "                                merge_mode='concat')(x)\n",
        "    x = layers.Dropout(rate=0.5)(x) if i < 5 else x  # Only between\n",
        "\n",
        "# Return at each time step logits along characters. Then CTC\n",
        "# computation is more stable, in contrast to the softmax.\n",
        "# x = layers.TimeDistributed(layers.Dense(units=rnn_units*2), name='dense_1')(x)\n",
        "# x = layers.ReLU(name='dense_1_relu')(x)\n",
        "# x = layers.Dropout(rate=0.5)(x)\n",
        "\n",
        "# output_tensor = layers.TimeDistributed(layers.Dense(units=output_dim),\n",
        "#                                        name='dense_2')(x)\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "x = layers.Dense(units=rnn_units*2)(x)\n",
        "x = layers.Dropout(rate=0.5)(x)\n",
        "\n",
        "output_tensor = layers.Dense(output_dim, activation='softmax')(x)\n",
        "model = keras.Model(input_tensor, output_tensor, name='DeepSpeech2')\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "             optimizer=keras.optimizers.Adam(lr=lr),\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "best_model_path = os.path.join(data_path, \"best_deepspeech.hdf5\")\n",
        "mcp_save = ModelCheckpoint(best_model_path, save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePAzBl-NuHn3",
        "colab_type": "code",
        "outputId": "b7d0b759-694c-4047-8043-a98a82b07342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Starting training from scratch\n",
        "# schedule = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "history = model.fit(train_dataset, validation_data=valid_dataset, class_weight=class_weight, shuffle=True, epochs=100, verbose=1, callbacks=[mcp_save, schedule])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.002.\n",
            "Epoch 1/100\n",
            "183/183 [==============================] - 188s 1s/step - loss: 2.5511 - accuracy: 0.1066 - val_loss: 9.8251 - val_accuracy: 0.0207 - lr: 0.0020\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.002.\n",
            "Epoch 2/100\n",
            "183/183 [==============================] - 186s 1s/step - loss: 0.6528 - accuracy: 0.1754 - val_loss: 3.0609 - val_accuracy: 0.0214 - lr: 0.0020\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 3/100\n",
            "183/183 [==============================] - 186s 1s/step - loss: 0.6147 - accuracy: 0.2090 - val_loss: 2.4900 - val_accuracy: 0.1569 - lr: 0.0010\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 4/100\n",
            "183/183 [==============================] - 184s 1s/step - loss: 0.6236 - accuracy: 0.2091 - val_loss: 3.0448 - val_accuracy: 0.1418 - lr: 0.0010\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 5/100\n",
            "183/183 [==============================] - 185s 1s/step - loss: 0.6166 - accuracy: 0.2059 - val_loss: 2.3884 - val_accuracy: 0.2010 - lr: 0.0010\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 6/100\n",
            "183/183 [==============================] - 182s 993ms/step - loss: 0.5917 - accuracy: 0.2069 - val_loss: 2.6309 - val_accuracy: 0.1585 - lr: 0.0010\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 7/100\n",
            "183/183 [==============================] - 178s 974ms/step - loss: 0.6115 - accuracy: 0.2367 - val_loss: 2.7600 - val_accuracy: 0.1680 - lr: 0.0010\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 8/100\n",
            "183/183 [==============================] - 181s 988ms/step - loss: 0.6152 - accuracy: 0.2042 - val_loss: 2.3243 - val_accuracy: 0.1872 - lr: 0.0010\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 9/100\n",
            "183/183 [==============================] - 181s 988ms/step - loss: 0.5627 - accuracy: 0.2466 - val_loss: 2.2470 - val_accuracy: 0.2189 - lr: 0.0010\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 10/100\n",
            "183/183 [==============================] - 182s 994ms/step - loss: 0.5367 - accuracy: 0.3285 - val_loss: 1.7313 - val_accuracy: 0.5204 - lr: 0.0010\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 11/100\n",
            "183/183 [==============================] - 181s 988ms/step - loss: 0.4215 - accuracy: 0.4695 - val_loss: 1.2881 - val_accuracy: 0.7026 - lr: 0.0010\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 12/100\n",
            "183/183 [==============================] - 177s 967ms/step - loss: 0.3858 - accuracy: 0.5126 - val_loss: 1.5331 - val_accuracy: 0.6449 - lr: 0.0010\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 13/100\n",
            "183/183 [==============================] - 176s 963ms/step - loss: 0.3990 - accuracy: 0.5138 - val_loss: 1.9107 - val_accuracy: 0.5232 - lr: 0.0010\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 14/100\n",
            "183/183 [==============================] - 176s 961ms/step - loss: 0.3947 - accuracy: 0.5274 - val_loss: 1.6357 - val_accuracy: 0.6118 - lr: 0.0010\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 15/100\n",
            "183/183 [==============================] - 179s 980ms/step - loss: 0.3776 - accuracy: 0.5420 - val_loss: 1.1588 - val_accuracy: 0.7423 - lr: 0.0010\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 16/100\n",
            "183/183 [==============================] - 177s 965ms/step - loss: 0.3427 - accuracy: 0.5792 - val_loss: 1.3607 - val_accuracy: 0.6914 - lr: 0.0010\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 17/100\n",
            "183/183 [==============================] - 176s 964ms/step - loss: 0.3600 - accuracy: 0.5481 - val_loss: 1.2521 - val_accuracy: 0.7417 - lr: 0.0010\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 18/100\n",
            "183/183 [==============================] - 176s 960ms/step - loss: 0.3695 - accuracy: 0.5568 - val_loss: 1.1694 - val_accuracy: 0.7453 - lr: 0.0010\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 19/100\n",
            "183/183 [==============================] - 177s 965ms/step - loss: 0.3328 - accuracy: 0.5908 - val_loss: 1.1804 - val_accuracy: 0.7641 - lr: 0.0010\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 20/100\n",
            "183/183 [==============================] - 180s 983ms/step - loss: 0.3178 - accuracy: 0.6022 - val_loss: 1.1172 - val_accuracy: 0.7889 - lr: 0.0010\n",
            "\n",
            "Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 21/100\n",
            "183/183 [==============================] - 177s 966ms/step - loss: 0.3178 - accuracy: 0.6085 - val_loss: 1.1270 - val_accuracy: 0.7792 - lr: 0.0010\n",
            "\n",
            "Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 22/100\n",
            "183/183 [==============================] - 177s 965ms/step - loss: 0.3076 - accuracy: 0.6318 - val_loss: 1.1493 - val_accuracy: 0.7072 - lr: 0.0010\n",
            "\n",
            "Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 23/100\n",
            "183/183 [==============================] - 178s 971ms/step - loss: 0.3465 - accuracy: 0.5942 - val_loss: 1.0073 - val_accuracy: 0.8077 - lr: 0.0010\n",
            "\n",
            "Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 24/100\n",
            "183/183 [==============================] - 177s 969ms/step - loss: 0.3193 - accuracy: 0.6120 - val_loss: 0.9329 - val_accuracy: 0.8291 - lr: 0.0010\n",
            "\n",
            "Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 25/100\n",
            "183/183 [==============================] - 174s 952ms/step - loss: 0.3141 - accuracy: 0.6111 - val_loss: 1.0714 - val_accuracy: 0.8176 - lr: 0.0010\n",
            "\n",
            "Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 26/100\n",
            "183/183 [==============================] - 173s 948ms/step - loss: 0.3019 - accuracy: 0.6292 - val_loss: 1.0194 - val_accuracy: 0.8025 - lr: 0.0010\n",
            "\n",
            "Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 27/100\n",
            "183/183 [==============================] - 173s 947ms/step - loss: 0.2953 - accuracy: 0.6454 - val_loss: 1.1085 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "\n",
            "Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 28/100\n",
            "183/183 [==============================] - 174s 948ms/step - loss: 0.2927 - accuracy: 0.6568 - val_loss: 1.0197 - val_accuracy: 0.8239 - lr: 0.0010\n",
            "\n",
            "Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 29/100\n",
            "183/183 [==============================] - 174s 951ms/step - loss: 0.2889 - accuracy: 0.6651 - val_loss: 1.0856 - val_accuracy: 0.8264 - lr: 0.0010\n",
            "\n",
            "Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 30/100\n",
            "183/183 [==============================] - 174s 951ms/step - loss: 0.2979 - accuracy: 0.6475 - val_loss: 0.9934 - val_accuracy: 0.8351 - lr: 0.0010\n",
            "\n",
            "Epoch 00031: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 31/100\n",
            "183/183 [==============================] - 174s 949ms/step - loss: 0.2882 - accuracy: 0.6652 - val_loss: 0.9353 - val_accuracy: 0.8546 - lr: 0.0010\n",
            "\n",
            "Epoch 00032: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 32/100\n",
            "183/183 [==============================] - 177s 967ms/step - loss: 0.2786 - accuracy: 0.6731 - val_loss: 1.6310 - val_accuracy: 0.5233 - lr: 0.0010\n",
            "\n",
            "Epoch 00033: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 33/100\n",
            "183/183 [==============================] - 178s 971ms/step - loss: 0.5133 - accuracy: 0.3251 - val_loss: 1.5659 - val_accuracy: 0.6492 - lr: 0.0010\n",
            "\n",
            "Epoch 00034: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 34/100\n",
            "183/183 [==============================] - 177s 965ms/step - loss: 0.3288 - accuracy: 0.5781 - val_loss: 1.2144 - val_accuracy: 0.7657 - lr: 0.0010\n",
            "\n",
            "Epoch 00035: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 35/100\n",
            "183/183 [==============================] - 175s 957ms/step - loss: 0.3164 - accuracy: 0.6281 - val_loss: 1.3693 - val_accuracy: 0.7490 - lr: 0.0010\n",
            "\n",
            "Epoch 00036: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 36/100\n",
            "183/183 [==============================] - 176s 960ms/step - loss: 0.2995 - accuracy: 0.6671 - val_loss: 1.1212 - val_accuracy: 0.8271 - lr: 0.0010\n",
            "\n",
            "Epoch 00037: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 37/100\n",
            "183/183 [==============================] - 176s 961ms/step - loss: 0.2860 - accuracy: 0.6803 - val_loss: 1.1325 - val_accuracy: 0.8115 - lr: 0.0010\n",
            "\n",
            "Epoch 00038: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 38/100\n",
            "183/183 [==============================] - 176s 960ms/step - loss: 0.2842 - accuracy: 0.6791 - val_loss: 1.1205 - val_accuracy: 0.8249 - lr: 0.0010\n",
            "\n",
            "Epoch 00039: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 39/100\n",
            "183/183 [==============================] - 176s 964ms/step - loss: 0.2743 - accuracy: 0.6889 - val_loss: 1.1552 - val_accuracy: 0.8292 - lr: 0.0010\n",
            "\n",
            "Epoch 00040: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 40/100\n",
            "183/183 [==============================] - 177s 969ms/step - loss: 0.2663 - accuracy: 0.7204 - val_loss: 1.1171 - val_accuracy: 0.8342 - lr: 0.0010\n",
            "\n",
            "Epoch 00041: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 41/100\n",
            "183/183 [==============================] - 177s 966ms/step - loss: 0.2593 - accuracy: 0.7304 - val_loss: 0.9808 - val_accuracy: 0.8291 - lr: 0.0010\n",
            "\n",
            "Epoch 00042: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 42/100\n",
            "183/183 [==============================] - 176s 961ms/step - loss: 0.2493 - accuracy: 0.7360 - val_loss: 0.9834 - val_accuracy: 0.8467 - lr: 0.0010\n",
            "\n",
            "Epoch 00043: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 43/100\n",
            "183/183 [==============================] - 176s 964ms/step - loss: 0.2599 - accuracy: 0.7278 - val_loss: 1.0860 - val_accuracy: 0.8347 - lr: 0.0010\n",
            "\n",
            "Epoch 00044: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 44/100\n",
            "183/183 [==============================] - 178s 973ms/step - loss: 0.2717 - accuracy: 0.7098 - val_loss: 1.0529 - val_accuracy: 0.8634 - lr: 0.0010\n",
            "\n",
            "Epoch 00045: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 45/100\n",
            "183/183 [==============================] - 177s 967ms/step - loss: 0.2531 - accuracy: 0.7340 - val_loss: 0.9632 - val_accuracy: 0.8595 - lr: 0.0010\n",
            "\n",
            "Epoch 00046: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 46/100\n",
            "183/183 [==============================] - 177s 969ms/step - loss: 0.2453 - accuracy: 0.7406 - val_loss: 1.0843 - val_accuracy: 0.8312 - lr: 0.0010\n",
            "\n",
            "Epoch 00047: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 47/100\n",
            "183/183 [==============================] - 179s 979ms/step - loss: 0.2448 - accuracy: 0.7486 - val_loss: 0.9211 - val_accuracy: 0.8504 - lr: 0.0010\n",
            "\n",
            "Epoch 00048: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 48/100\n",
            "183/183 [==============================] - 180s 983ms/step - loss: 0.2463 - accuracy: 0.7449 - val_loss: 0.9069 - val_accuracy: 0.8509 - lr: 0.0010\n",
            "\n",
            "Epoch 00049: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 49/100\n",
            "183/183 [==============================] - 177s 966ms/step - loss: 0.2419 - accuracy: 0.7536 - val_loss: 0.9446 - val_accuracy: 0.8578 - lr: 0.0010\n",
            "\n",
            "Epoch 00050: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 50/100\n",
            "183/183 [==============================] - 178s 973ms/step - loss: 0.2385 - accuracy: 0.7576 - val_loss: 0.9664 - val_accuracy: 0.8768 - lr: 0.0010\n",
            "\n",
            "Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 51/100\n",
            "183/183 [==============================] - 180s 985ms/step - loss: 0.2288 - accuracy: 0.7688 - val_loss: 0.8912 - val_accuracy: 0.8760 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 52/100\n",
            "183/183 [==============================] - 180s 981ms/step - loss: 0.2219 - accuracy: 0.7733 - val_loss: 0.8301 - val_accuracy: 0.8818 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 53/100\n",
            "183/183 [==============================] - 182s 993ms/step - loss: 0.2258 - accuracy: 0.7716 - val_loss: 0.8142 - val_accuracy: 0.8917 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00054: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 54/100\n",
            "183/183 [==============================] - 186s 1s/step - loss: 0.2180 - accuracy: 0.7755 - val_loss: 0.7683 - val_accuracy: 0.8957 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00055: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 55/100\n",
            "183/183 [==============================] - 187s 1s/step - loss: 0.2145 - accuracy: 0.7773 - val_loss: 0.8257 - val_accuracy: 0.8884 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00056: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 56/100\n",
            "183/183 [==============================] - 182s 994ms/step - loss: 0.2190 - accuracy: 0.7782 - val_loss: 0.8599 - val_accuracy: 0.8798 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00057: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 57/100\n",
            "183/183 [==============================] - 178s 974ms/step - loss: 0.2151 - accuracy: 0.7736 - val_loss: 0.8177 - val_accuracy: 0.8816 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00058: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 58/100\n",
            "183/183 [==============================] - 178s 974ms/step - loss: 0.2140 - accuracy: 0.7779 - val_loss: 0.8019 - val_accuracy: 0.8856 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00059: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 59/100\n",
            "183/183 [==============================] - 177s 970ms/step - loss: 0.2173 - accuracy: 0.7790 - val_loss: 0.8034 - val_accuracy: 0.8949 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00060: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 60/100\n",
            "183/183 [==============================] - 177s 967ms/step - loss: 0.2160 - accuracy: 0.7798 - val_loss: 0.7993 - val_accuracy: 0.8927 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00061: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 61/100\n",
            "183/183 [==============================] - 177s 968ms/step - loss: 0.2233 - accuracy: 0.7752 - val_loss: 0.7859 - val_accuracy: 0.8898 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00062: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 62/100\n",
            "183/183 [==============================] - 175s 956ms/step - loss: 0.2136 - accuracy: 0.7804 - val_loss: 0.8177 - val_accuracy: 0.8861 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00063: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 63/100\n",
            "183/183 [==============================] - 175s 957ms/step - loss: 0.2105 - accuracy: 0.7826 - val_loss: 0.7965 - val_accuracy: 0.8933 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00064: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 64/100\n",
            "183/183 [==============================] - 174s 949ms/step - loss: 0.2140 - accuracy: 0.7790 - val_loss: 0.8383 - val_accuracy: 0.8814 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00065: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 65/100\n",
            "183/183 [==============================] - 174s 952ms/step - loss: 0.2129 - accuracy: 0.7802 - val_loss: 0.8217 - val_accuracy: 0.8875 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00066: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 66/100\n",
            "183/183 [==============================] - 174s 948ms/step - loss: 0.2103 - accuracy: 0.7840 - val_loss: 0.8388 - val_accuracy: 0.8813 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00067: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 67/100\n",
            "183/183 [==============================] - 174s 950ms/step - loss: 0.2138 - accuracy: 0.7807 - val_loss: 0.8055 - val_accuracy: 0.8963 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00068: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 68/100\n",
            "183/183 [==============================] - 174s 949ms/step - loss: 0.2121 - accuracy: 0.7846 - val_loss: 0.7725 - val_accuracy: 0.8902 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00069: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 69/100\n",
            "183/183 [==============================] - 178s 973ms/step - loss: 0.2147 - accuracy: 0.7816 - val_loss: 0.7644 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00070: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 70/100\n",
            "183/183 [==============================] - 176s 961ms/step - loss: 0.2058 - accuracy: 0.7865 - val_loss: 0.8220 - val_accuracy: 0.8801 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00071: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 71/100\n",
            "183/183 [==============================] - 175s 954ms/step - loss: 0.2098 - accuracy: 0.7853 - val_loss: 0.7791 - val_accuracy: 0.8905 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00072: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 72/100\n",
            "183/183 [==============================] - 175s 954ms/step - loss: 0.2089 - accuracy: 0.7872 - val_loss: 0.7855 - val_accuracy: 0.8867 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00073: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 73/100\n",
            "183/183 [==============================] - 174s 952ms/step - loss: 0.2049 - accuracy: 0.7878 - val_loss: 0.8223 - val_accuracy: 0.8790 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00074: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 74/100\n",
            "183/183 [==============================] - 175s 955ms/step - loss: 0.2071 - accuracy: 0.7894 - val_loss: 0.7779 - val_accuracy: 0.8876 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00075: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 75/100\n",
            "183/183 [==============================] - 175s 956ms/step - loss: 0.2084 - accuracy: 0.7888 - val_loss: 0.8092 - val_accuracy: 0.8819 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 00076: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 76/100\n",
            "183/183 [==============================] - 174s 950ms/step - loss: 0.2034 - accuracy: 0.7951 - val_loss: 0.8207 - val_accuracy: 0.8808 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00077: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 77/100\n",
            "183/183 [==============================] - 174s 951ms/step - loss: 0.2075 - accuracy: 0.7879 - val_loss: 0.7774 - val_accuracy: 0.8912 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00078: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 78/100\n",
            "183/183 [==============================] - 176s 962ms/step - loss: 0.2020 - accuracy: 0.7936 - val_loss: 0.7508 - val_accuracy: 0.8946 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00079: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 79/100\n",
            "183/183 [==============================] - 177s 968ms/step - loss: 0.2046 - accuracy: 0.7925 - val_loss: 0.7507 - val_accuracy: 0.8953 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00080: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 80/100\n",
            "183/183 [==============================] - 174s 953ms/step - loss: 0.2051 - accuracy: 0.7908 - val_loss: 0.7577 - val_accuracy: 0.8984 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00081: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 81/100\n",
            "183/183 [==============================] - 174s 953ms/step - loss: 0.2014 - accuracy: 0.7915 - val_loss: 0.7771 - val_accuracy: 0.8908 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00082: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 82/100\n",
            "183/183 [==============================] - 175s 955ms/step - loss: 0.2047 - accuracy: 0.7926 - val_loss: 0.7791 - val_accuracy: 0.8918 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00083: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 83/100\n",
            "183/183 [==============================] - 174s 952ms/step - loss: 0.2035 - accuracy: 0.7909 - val_loss: 0.7823 - val_accuracy: 0.8913 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00084: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 84/100\n",
            "183/183 [==============================] - 175s 956ms/step - loss: 0.2037 - accuracy: 0.7939 - val_loss: 0.8003 - val_accuracy: 0.8828 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00085: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 85/100\n",
            "183/183 [==============================] - 174s 951ms/step - loss: 0.1985 - accuracy: 0.7968 - val_loss: 0.7524 - val_accuracy: 0.8946 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00086: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 86/100\n",
            "183/183 [==============================] - 174s 952ms/step - loss: 0.2040 - accuracy: 0.7894 - val_loss: 0.7616 - val_accuracy: 0.8916 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00087: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 87/100\n",
            "183/183 [==============================] - 173s 946ms/step - loss: 0.2091 - accuracy: 0.7868 - val_loss: 0.7879 - val_accuracy: 0.8927 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00088: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 88/100\n",
            "183/183 [==============================] - 177s 965ms/step - loss: 0.2017 - accuracy: 0.7913 - val_loss: 0.7222 - val_accuracy: 0.9036 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00089: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 89/100\n",
            "183/183 [==============================] - 175s 957ms/step - loss: 0.2062 - accuracy: 0.7891 - val_loss: 0.8066 - val_accuracy: 0.8849 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00090: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 90/100\n",
            "183/183 [==============================] - 174s 951ms/step - loss: 0.2073 - accuracy: 0.7905 - val_loss: 0.7842 - val_accuracy: 0.8913 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00091: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 91/100\n",
            "183/183 [==============================] - 174s 953ms/step - loss: 0.2075 - accuracy: 0.7876 - val_loss: 0.8011 - val_accuracy: 0.8858 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00092: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 92/100\n",
            "183/183 [==============================] - 173s 946ms/step - loss: 0.2075 - accuracy: 0.7888 - val_loss: 0.8001 - val_accuracy: 0.8859 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00093: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 93/100\n",
            "183/183 [==============================] - 173s 948ms/step - loss: 0.2057 - accuracy: 0.7922 - val_loss: 0.8346 - val_accuracy: 0.8799 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00094: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 94/100\n",
            "183/183 [==============================] - 173s 946ms/step - loss: 0.1990 - accuracy: 0.7935 - val_loss: 0.7760 - val_accuracy: 0.8907 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00095: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 95/100\n",
            "183/183 [==============================] - 174s 952ms/step - loss: 0.2071 - accuracy: 0.7911 - val_loss: 0.8344 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00096: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 96/100\n",
            "183/183 [==============================] - 175s 954ms/step - loss: 0.2017 - accuracy: 0.7940 - val_loss: 0.8124 - val_accuracy: 0.8795 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00097: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 97/100\n",
            "183/183 [==============================] - 174s 950ms/step - loss: 0.2057 - accuracy: 0.7937 - val_loss: 0.7879 - val_accuracy: 0.8863 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00098: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 98/100\n",
            "183/183 [==============================] - 174s 953ms/step - loss: 0.2025 - accuracy: 0.7892 - val_loss: 0.7785 - val_accuracy: 0.8897 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00099: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 99/100\n",
            "183/183 [==============================] - 174s 951ms/step - loss: 0.2037 - accuracy: 0.7919 - val_loss: 0.7694 - val_accuracy: 0.8931 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00100: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 100/100\n",
            "183/183 [==============================] - 175s 955ms/step - loss: 0.2062 - accuracy: 0.7890 - val_loss: 0.7979 - val_accuracy: 0.8856 - lr: 1.0000e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGFvjWub0S68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Traininig continuation\n",
        "model = keras.models.load_model(best_model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_HK8xRkB0nR",
        "colab_type": "code",
        "outputId": "bad2f0f9-a125-4d5f-8681-95c745372945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.optimizer.lr = 0.001\n",
        "model.optimizer.lr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqmCrGoRBzJC",
        "colab_type": "code",
        "outputId": "2938963f-86d2-44bc-bb16-3f65bc9f96b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "history = model.fit(train_dataset, validation_data=valid_dataset, class_weight=class_weight, shuffle=True, epochs=100, verbose=1, callbacks=[mcp_save])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "183/183 [==============================] - 414s 2s/step - loss: 0.3540 - accuracy: 0.6663 - val_loss: 0.8491 - val_accuracy: 0.8780\n",
            "Epoch 2/100\n",
            "183/183 [==============================] - 288s 2s/step - loss: 0.2239 - accuracy: 0.7722 - val_loss: 0.8639 - val_accuracy: 0.8717\n",
            "Epoch 3/100\n",
            "183/183 [==============================] - 291s 2s/step - loss: 0.2224 - accuracy: 0.7766 - val_loss: 0.7555 - val_accuracy: 0.8753\n",
            "Epoch 4/100\n",
            "183/183 [==============================] - 288s 2s/step - loss: 0.2175 - accuracy: 0.7819 - val_loss: 0.9601 - val_accuracy: 0.8525\n",
            "Epoch 5/100\n",
            "183/183 [==============================] - 287s 2s/step - loss: 0.2182 - accuracy: 0.7767 - val_loss: 0.8938 - val_accuracy: 0.8669\n",
            "Epoch 6/100\n",
            "183/183 [==============================] - 287s 2s/step - loss: 0.2158 - accuracy: 0.7835 - val_loss: 0.9036 - val_accuracy: 0.8689\n",
            "Epoch 7/100\n",
            "183/183 [==============================] - 287s 2s/step - loss: 0.2121 - accuracy: 0.7848 - val_loss: 0.8759 - val_accuracy: 0.8666\n",
            "Epoch 8/100\n",
            "183/183 [==============================] - 288s 2s/step - loss: 0.2119 - accuracy: 0.7836 - val_loss: 0.9953 - val_accuracy: 0.8422\n",
            "Epoch 9/100\n",
            "183/183 [==============================] - 290s 2s/step - loss: 0.2041 - accuracy: 0.7865 - val_loss: 0.7436 - val_accuracy: 0.8788\n",
            "Epoch 10/100\n",
            "183/183 [==============================] - 286s 2s/step - loss: 0.2068 - accuracy: 0.7893 - val_loss: 0.9016 - val_accuracy: 0.8771\n",
            "Epoch 11/100\n",
            "183/183 [==============================] - 288s 2s/step - loss: 0.2079 - accuracy: 0.7854 - val_loss: 0.7411 - val_accuracy: 0.8876\n",
            "Epoch 12/100\n",
            "183/183 [==============================] - 285s 2s/step - loss: 0.2104 - accuracy: 0.7871 - val_loss: 0.9371 - val_accuracy: 0.8478\n",
            "Epoch 13/100\n",
            "183/183 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.7904"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnKLqFhN9CnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model_path = os.path.join(data_path, \"best_deepspeech.hdf5\")\n",
        "model = keras.models.load_model(best_model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6f47mrgeCMB",
        "colab_type": "code",
        "outputId": "99e31960-e07a-4e2c-d8c5-642a203b25e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"DeepSpeech2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 33, 161, 1)]      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 33, 161, 1)        644       \n",
            "_________________________________________________________________\n",
            "conv_1 (Conv2D)              (None, 17, 81, 32)        14432     \n",
            "_________________________________________________________________\n",
            "conv_1_bn (BatchNormalizatio (None, 17, 81, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv_1_relu (ReLU)           (None, 17, 81, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_2 (Conv2D)              (None, 17, 41, 32)        236544    \n",
            "_________________________________________________________________\n",
            "conv_2_bn (BatchNormalizatio (None, 17, 41, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv_2_relu (ReLU)           (None, 17, 41, 32)        0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 17, 1312)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 17, 1024)          5609472   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 17, 1024)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 17, 1024)          4724736   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 17, 1024)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 17408)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              17826816  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 12)                12300     \n",
            "=================================================================\n",
            "Total params: 28,425,200\n",
            "Trainable params: 28,424,750\n",
            "Non-trainable params: 450\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b6Bmzp5SxLA",
        "colab_type": "text"
      },
      "source": [
        "## Running model on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4ROrEW0iDOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dict = {'down': 0,\n",
        "            'go': 1,\n",
        "            'left': 2,\n",
        "            'no': 3,\n",
        "            'off': 4,\n",
        "            'on': 5,\n",
        "            'right': 6,\n",
        "            'silence': 7,\n",
        "            'stop': 8,\n",
        "            'unknown': 9,\n",
        "            'up': 10,\n",
        "            'yes': 11}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBFGgqvJXJNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_path = os.path.join(data_path, \"test_wav_final.npy\")\n",
        "test_all = np.load(test_path)  # may take a while (~3 minutes) (it's almost 5GB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of72QntpSbMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del(train_wav_spec)\n",
        "del(test_wav_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXyO7vTskWrm",
        "colab_type": "code",
        "outputId": "f28b684a-2900-46a0-be35-935f46e5861a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "chunk_size = 8096\n",
        "n_steps = test_all.shape[0] // chunk_size\n",
        "n_steps"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMzg3eivj24k",
        "colab_type": "code",
        "outputId": "aae4fd3b-6888-44ab-f079-b9a6e0bb8a77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "8ea362f02f0947628f6cbafeb8397f3a",
            "710ddab56e624a91b4e5aa7bcc25188c",
            "85d3567007104861a131b6c4abc70fc6",
            "d12421473aa64beaa9b54c19729a3d50",
            "fdd2ce8092dd410eb0b5a3d8bdfe4a1d",
            "4474444352b241a6b8bff270359d5b1e",
            "6f2ea57788db47a69a87a9369771f8b1",
            "7e311a54ceb4406bb93a166be73fa94d"
          ]
        }
      },
      "source": [
        "preds_all = []\n",
        "sample_rate = 8000\n",
        "for i in trange(n_steps+1):\n",
        "    if i==n_steps:\n",
        "        spectograms_test = [log_specgram(np.squeeze(elem))\\\n",
        "                         for elem in test_all[i*chunk_size:]]\n",
        "    else:\n",
        "        spectograms_test = [log_specgram(np.squeeze(elem))\\\n",
        "                         for elem in test_all[i*chunk_size:i*chunk_size + chunk_size]]\n",
        "    spectograms_test = np.asarray(spectograms_test)\n",
        "    spectograms_test = np.expand_dims(spectograms_test, axis=3)\n",
        "    preds_all.append(model.predict(spectograms_test))\n",
        "preds = np.array([item for sublist in preds_all for item in sublist])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ea362f02f0947628f6cbafeb8397f3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpfMNgwfnIRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = np.array(preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKFz_71mYk8q",
        "colab_type": "code",
        "outputId": "50580588-2582-4aad-e846-b042424de6e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "num_to_label = {value: key for key, value in label_dict.items()}\n",
        "num_to_label"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'down',\n",
              " 1: 'go',\n",
              " 2: 'left',\n",
              " 3: 'no',\n",
              " 4: 'off',\n",
              " 5: 'on',\n",
              " 6: 'right',\n",
              " 7: 'silence',\n",
              " 8: 'stop',\n",
              " 9: 'unknown',\n",
              " 10: 'up',\n",
              " 11: 'yes'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LrrfW0lYmcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_labels = [num_to_label[num] for num in preds.argmax(1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iEeRA-xZgwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_file = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))\n",
        "submission_file[\"label\"] = predicted_labels\n",
        "submission_file.to_csv(os.path.join(data_path, \"submission_deepspeech.csv\"), index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrZIrwUdaUc_",
        "colab_type": "code",
        "outputId": "5a63b98e-3d0b-47b4-a72e-91b4c3360c44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "pd.read_csv(os.path.join(data_path, \"submission_deepspeech.csv\")).head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>clip_000044442.wav</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>clip_0000adecb.wav</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>clip_0000d4322.wav</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>clip_0000fb6fe.wav</td>\n",
              "      <td>silence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>clip_0001d1559.wav</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                fname    label\n",
              "0  clip_000044442.wav       no\n",
              "1  clip_0000adecb.wav  unknown\n",
              "2  clip_0000d4322.wav  unknown\n",
              "3  clip_0000fb6fe.wav  silence\n",
              "4  clip_0001d1559.wav  unknown"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOUv_pm9jDJm",
        "colab_type": "code",
        "outputId": "94e75c8d-dc73-459f-cc2f-c5eecf551ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "predicted_label_cnt = Counter(submission_file.label.values)\n",
        "plt.bar(predicted_label_cnt.keys(), predicted_label_cnt.values())\n",
        "plt.xticks(rotation=45)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
              " <a list of 12 Text major ticklabel objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEVCAYAAAACW4lMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de5wddX3/8debhEAAISGsKSSBxBLBQMtthVDwAmjYcDGUmyCaiJGoXLxha1BrKkgFW0Vplf6iBAIiELFIhNCYAq22NcAiN7k1y80k3FYSLoqCCZ/fH9/PmjHsZs/unj2bkPfz8TiPnfnOnO/MOTtnPvO9zHcUEZiZ2cZtk4HeATMzG3gOBmZm5mBgZmYOBmZmhoOBmZkBgwd6B3pru+22i7Fjxw70bpiZbTDuuOOOX0dEU2fLNthgMHbsWFpbWwd6N8zMNhiSHu9qWU3VRJI+Jek+Sb+UdKWkzSWNk3SrpDZJV0sakutulvNtuXxsJZ+zMv0hSYdW0lsyrU3SzN5/VDMz641ug4GkUcDHgeaI2B0YBJwAnA9cEBE7AyuB6fmW6cDKTL8g10PShHzfbkAL8G1JgyQNAr4FTAYmACfmumZm1iC1NiAPBoZKGgxsATwJHAxck8vnAkfl9JScJ5cfIkmZflVEvBwRjwJtwL75aouIRyLiFeCqXNfMzBqk22AQEcuBfwJ+RQkCzwN3AM9FxKpcbRkwKqdHAUvzvaty/RHV9LXe01X6a0iaIalVUmt7e3stn8/MzGpQSzXRcMqV+jhgB2BLSjVPw0XE7IhojojmpqZOG8TNzKwXaqkmehfwaES0R8QfgH8DDgCGZbURwGhgeU4vB8YA5PJtgGer6Wu9p6t0MzNrkFqCwa+AiZK2yLr/Q4D7gVuAY3OdacB1OT0/58nlN0cZGnU+cEL2NhoHjAduA24HxmfvpCGURub5ff9oZmZWq27vM4iIWyVdA/wCWAXcCcwGbgCukvTlTLs433IxcLmkNmAF5eRORNwnaR4lkKwCTouI1QCSTgcWUnoqzYmI++r3Ec3MrDvaUJ9n0NzcHL7pzMysdpLuiIjmzpZtsHcgbwjGzryhrvk9dt7hdc3PzKyDB6ozMzMHAzMzczAwMzMcDMzMDAcDMzPDwcDMzHAwMDMzHAzMzAwHAzMzw8HAzMxwMDAzMxwMzMwMBwMzM8PBwMzMcDAwMzMcDMzMDAcDMzOjhmAgaRdJd1VeL0j6pKRtJS2StCT/Ds/1JelCSW2S7pG0dyWvabn+EknTKun7SLo333OhJPXPxzUzs850Gwwi4qGI2DMi9gT2AV4CrgVmAjdFxHjgppwHmAyMz9cM4CIASdsCs4D9gH2BWR0BJNc5pfK+lrp8OjMzq0lPq4kOAR6OiMeBKcDcTJ8LHJXTU4DLolgMDJO0PXAosCgiVkTESmAR0JLLto6IxRERwGWVvMzMrAF6GgxOAK7M6ZER8WROPwWMzOlRwNLKe5Zl2rrSl3WS/hqSZkhqldTa3t7ew103M7Ou1BwMJA0B3gP8YO1leUUfddyvTkXE7Ihojojmpqam/t6cmdlGoyclg8nALyLi6Zx/Oqt4yL/PZPpyYEzlfaMzbV3poztJNzOzBulJMDiRNVVEAPOBjh5B04DrKulTs1fRROD5rE5aCEySNDwbjicBC3PZC5ImZi+iqZW8zMysAQbXspKkLYF3Ax+pJJ8HzJM0HXgcOD7TFwCHAW2UnkcnA0TECknnALfnemdHxIqcPhW4FBgK3JgvMzNrkJqCQUT8FhixVtqzlN5Fa68bwGld5DMHmNNJeiuwey37YmZm9ec7kM3MzMHAzMwcDMzMDAcDMzPDwcDMzHAwMDMzHAzMzAwHAzMzw8HAzMxwMDAzMxwMzMwMBwMzM8PBwMzMcDAwMzMcDMzMDAcDMzPDwcDMzKgxGEgaJukaSQ9KekDS/pK2lbRI0pL8OzzXlaQLJbVJukfS3pV8puX6SyRNq6TvI+nefM+F+SxkMzNrkFpLBt8E/j0idgX2AB4AZgI3RcR44KacB5gMjM/XDOAiAEnbArOA/YB9gVkdASTXOaXyvpa+fSwzM+uJboOBpG2AtwMXA0TEKxHxHDAFmJurzQWOyukpwGVRLAaGSdoeOBRYFBErImIlsAhoyWVbR8TifH7yZZW8zMysAWopGYwD2oFLJN0p6buStgRGRsSTuc5TwMicHgUsrbx/WaatK31ZJ+mvIWmGpFZJre3t7TXsupmZ1aKWYDAY2Bu4KCL2An7LmiohAPKKPuq/e38qImZHRHNENDc1NfX35szMNhq1BINlwLKIuDXnr6EEh6eziof8+0wuXw6Mqbx/dKatK310J+lmZtYg3QaDiHgKWCppl0w6BLgfmA909AiaBlyX0/OBqdmraCLwfFYnLQQmSRqeDceTgIW57AVJE7MX0dRKXmZm1gCDa1zvDOAKSUOAR4CTKYFknqTpwOPA8bnuAuAwoA14KdclIlZIOge4Pdc7OyJW5PSpwKXAUODGfJmZWYPUFAwi4i6guZNFh3SybgCndZHPHGBOJ+mtwO617IuZmdWf70A2MzMHAzMzczAwMzMcDMzMDAcDMzPDwcDMzHAwMDMzHAzMzAwHAzMzw8HAzMxwMDAzMxwMzMwMBwMzM8PBwMzMcDAwMzMcDMzMDAcDMzPDwcDMzKgxGEh6TNK9ku6S1Jpp20paJGlJ/h2e6ZJ0oaQ2SfdI2ruSz7Rcf4mkaZX0fTL/tnyv6v1Bzcysaz0pGRwUEXtGRMezkGcCN0XEeOCmnAeYDIzP1wzgIijBA5gF7AfsC8zqCCC5zimV97X0+hOZmVmP9aWaaAowN6fnAkdV0i+LYjEwTNL2wKHAoohYERErgUVASy7bOiIWR0QAl1XyMjOzBqg1GATwE0l3SJqRaSMj4smcfgoYmdOjgKWV9y7LtHWlL+sk/TUkzZDUKqm1vb29xl03M7PuDK5xvQMjYrmkNwKLJD1YXRgRISnqv3t/KiJmA7MBmpub+317ZmYbi5pKBhGxPP8+A1xLqfN/Oqt4yL/P5OrLgTGVt4/OtHWlj+4k3czMGqTbYCBpS0lv6JgGJgG/BOYDHT2CpgHX5fR8YGr2KpoIPJ/VSQuBSZKGZ8PxJGBhLntB0sTsRTS1kpeZmTVALdVEI4Frs7fnYOD7EfHvkm4H5kmaDjwOHJ/rLwAOA9qAl4CTASJihaRzgNtzvbMjYkVOnwpcCgwFbsyXmZk1SLfBICIeAfboJP1Z4JBO0gM4rYu85gBzOklvBXavYX/NzKwf+A5kMzNzMDAzMwcDMzPDwcDMzHAwMDMzHAzMzAwHAzMzw8HAzMxwMDAzMxwMzMwMBwMzM8PBwMzMcDAwMzMcDMzMDAcDMzPDwcDMzHAwMDMzehAMJA2SdKek63N+nKRbJbVJulrSkEzfLOfbcvnYSh5nZfpDkg6tpLdkWpukmfX7eGZmVouelAw+ATxQmT8fuCAidgZWAtMzfTqwMtMvyPWQNAE4AdgNaAG+nQFmEPAtYDIwATgx1zUzswapKRhIGg0cDnw35wUcDFyTq8wFjsrpKTlPLj8k158CXBURL0fEo0AbsG++2iLikYh4Bbgq1zUzswaptWTwDeBvgVdzfgTwXESsyvllwKicHgUsBcjlz+f6f0xf6z1dpb+GpBmSWiW1tre317jrZmbWnW6DgaQjgGci4o4G7M86RcTsiGiOiOampqaB3h0zs9eNwTWscwDwHkmHAZsDWwPfBIZJGpxX/6OB5bn+cmAMsEzSYGAb4NlKeofqe7pKNzOzBui2ZBARZ0XE6IgYS2kAvjkiTgJuAY7N1aYB1+X0/Jwnl98cEZHpJ2Rvo3HAeOA24HZgfPZOGpLbmF+XT2dmZjWppWTQlc8CV0n6MnAncHGmXwxcLqkNWEE5uRMR90maB9wPrAJOi4jVAJJOBxYCg4A5EXFfH/bLzMx6qEfBICL+E/jPnH6E0hNo7XV+DxzXxfvPBc7tJH0BsKAn+2JmZvXjO5DNzMzBwMzMHAzMzAwHAzMzw8HAzMxwMDAzMxwMzMwMBwMzM8PBwMzMcDAwMzMcDMzMDAcDMzPDwcDMzHAwMDMzHAzMzAwHAzMzw8HAzMxwMDAzM2oIBpI2l3SbpLsl3SfpS5k+TtKtktokXZ0PsycfeH91pt8qaWwlr7My/SFJh1bSWzKtTdLM+n9MMzNbl1pKBi8DB0fEHsCeQIukicD5wAURsTOwEpie608HVmb6BbkekiYAJwC7AS3AtyUNkjQI+BYwGZgAnJjrmplZg3QbDKL4Tc5umq8ADgauyfS5wFE5PSXnyeWHSFKmXxURL0fEo0AbsG++2iLikYh4Bbgq1zUzswapqc0gr+DvAp4BFgEPA89FxKpcZRkwKqdHAUsBcvnzwIhq+lrv6Sq9s/2YIalVUmt7e3stu25mZjWoKRhExOqI2BMYTbmS37Vf96rr/ZgdEc0R0dzU1DQQu2Bm9rrUo95EEfEccAuwPzBM0uBcNBpYntPLgTEAuXwb4Nlq+lrv6SrdzMwapJbeRE2ShuX0UODdwAOUoHBsrjYNuC6n5+c8ufzmiIhMPyF7G40DxgO3AbcD47N30hBKI/P8enw4MzOrzeDuV2F7YG72+tkEmBcR10u6H7hK0peBO4GLc/2LgcsltQErKCd3IuI+SfOA+4FVwGkRsRpA0unAQmAQMCci7qvbJzQzs251Gwwi4h5gr07SH6G0H6yd/nvguC7yOhc4t5P0BcCCGvbXzMz6ge9ANjMzBwMzM3MwMDMzHAzMzAwHAzMzw8HAzMxwMDAzMxwMzMwMBwMzM8PBwMzMcDAwMzMcDMzMDAcDMzPDwcDMzHAwMDMzHAzMzAwHAzMzo7ZnII+RdIuk+yXdJ+kTmb6tpEWSluTf4ZkuSRdKapN0j6S9K3lNy/WXSJpWSd9H0r35ngslqT8+rJmZda6WksEq4MyImABMBE6TNAGYCdwUEeOBm3IeYDLlYffjgRnARVCCBzAL2I/yuMxZHQEk1zml8r6Wvn80MzOrVbfBICKejIhf5PSLwAPAKGAKMDdXmwscldNTgMuiWAwMk7Q9cCiwKCJWRMRKYBHQksu2jojFERHAZZW8zMysAXrUZiBpLLAXcCswMiKezEVPASNzehSwtPK2ZZm2rvRlnaSbmVmD1BwMJG0F/BD4ZES8UF2WV/RR533rbB9mSGqV1Nre3t7fmzMz22jUFAwkbUoJBFdExL9l8tNZxUP+fSbTlwNjKm8fnWnrSh/dSfprRMTsiGiOiOampqZadt3MzGpQS28iARcDD0TE1yuL5gMdPYKmAddV0qdmr6KJwPNZnbQQmCRpeDYcTwIW5rIXJE3MbU2t5GVmZg0wuIZ1DgA+ANwr6a5M+xxwHjBP0nTgceD4XLYAOAxoA14CTgaIiBWSzgFuz/XOjogVOX0qcCkwFLgxX2Zm1iDdBoOI+G+gq37/h3SyfgCndZHXHGBOJ+mtwO7d7YuZmfUP34FsZmYOBmZm5mBgZmY4GJiZGQ4GZmaGg4GZmeFgYGZm1HbTma3Hxs68oe55Pnbe4XXP08zWby4ZmJmZg4GZmTkYmJkZDgZmZoaDgZmZ4WBgZmY4GJiZGQ4GZmaGg4GZmeFgYGZm1BAMJM2R9IykX1bStpW0SNKS/Ds80yXpQkltku6RtHflPdNy/SWSplXS95F0b77nQkldPWLTzMz6SS0lg0uBlrXSZgI3RcR44KacB5gMjM/XDOAiKMEDmAXsB+wLzOoIILnOKZX3rb0tMzPrZ90Gg4j4KbBireQpwNycngscVUm/LIrFwDBJ2wOHAosiYkVErAQWAS25bOuIWBwRAVxWycvMzBqkt20GIyPiyZx+ChiZ06OApZX1lmXautKXdZLeKUkzJLVKam1vb+/lrpuZ2dr63ICcV/RRh32pZVuzI6I5IpqbmpoasUkzs41Cb4PB01nFQ/59JtOXA2Mq643OtHWlj+4k3czMGqi3wWA+0NEjaBpwXSV9avYqmgg8n9VJC4FJkoZnw/EkYGEue0HSxOxFNLWSl5mZNUi3TzqTdCXwTmA7ScsovYLOA+ZJmg48Dhyfqy8ADgPagJeAkwEiYoWkc4Dbc72zI6KjUfpUSo+locCN+TIzswbqNhhExIldLDqkk3UDOK2LfOYAczpJbwV2724/zMys//gOZDMz675kYPZ6NHbmDXXN77HzDq9rfmaN5mBgNan3yRN8AjVbn2yUwcBXhesvB52e83fWOz4P/KmNMhiYmTXKhhJ0HAzM+tGGciJYn7ikMzAcDMysJj5Jv765a6mZmTkYmJmZg4GZmeFgYGZmOBiYmRkOBmZmhoOBmZnhYGBmZjgYmJkZDgZmZoaDgZmZsR4FA0ktkh6S1CZp5kDvj5nZxmS9CAaSBgHfAiYDE4ATJU0Y2L0yM9t4rBfBANgXaIuIRyLiFeAqYMoA75OZ2UZDETHQ+4CkY4GWiPhwzn8A2C8iTl9rvRnAjJzdBXion3dtO+DX/byN19t2Xk+fxdtZf7fh7fTOThHR1NmCDep5BhExG5jdqO1Jao2IZm9n/dqGt7N+b+f19Flej9vpyvpSTbQcGFOZH51pZmbWAOtLMLgdGC9pnKQhwAnA/AHeJzOzjcZ6UU0UEasknQ4sBAYBcyLivgHeLWhcldTraTuvp8/i7ay/2/B26my9aEA2M7OBtb5UE5mZ2QByMDAzMwcDs3WRNEKSBno/zPqbg8EGpOOk1F8nJ5/0/pSkI4CzgWEDvS8bsrWPqw3tOJPU0I42kjaXNDynt88elv3OwaAHJA3Y9yVJsaa1f0Q9863MblqvfLvIv5757iBpM0lb5Xxd/zeStgT+HvghsEXHdvpb/vi36OdtvOZ/0p8XGB3HraShABEROR5ZPbfTL7/N/L/vktOTJW3fH9upbG8TYE/gg5I+ApwHbNOf2+ywXnQtXV9JOgkYB7wIXBsRv5K0SUS82uD9qP6gzqAcKAuBn0XEjX3Ju5LvdGCipLuB+yPi5l7u68nAjsBPgTsi4oW1AlmfSWoBZgEPAltK+lxEtNXrfyPpr4DHgP8HfJXyY3xzvT9HJ9t9D/Ah4G+AJf21nTwZvw3YHvhNRCzItLoe22sdt58GmvMq+wMR8bKkQRGxug/5dwxmuTIinuyH4+wgYB9gW0mjgf0o46j1m4h4VdITwDuA/YEzI6K9Eecdlwy6IOk04AxKINgJ+KGknRsdCOBPTtiHUQ7ITwMvA++WdFxf85f0YWAacAkwHfirXuYzBfgYZYyV9wEfljQ8TzR1ufKU9CbgQuBvga8AtwFXSBpTp0AwEbgM2Jzy+9iRMgbWZh0nzL5uo4vtvg34EvDFiFiSVQXb5LJ6fXcd1YxvBS4FDgY+JOkH8McTUd1KCJXjdhJwNPCPwO+BVkmbRcTq3pYQJB0KLAI+CyyWtH89/z+S/hL4NuVY+APwHuBbEfF8PfLvYpubAETEr4AHgJuB3SS9pePY7s8qNgeDtVS+7L8APh4R34yITwPXAH/XUdQdgP3aGfge0BoR/wV8B3gE2D9LMD3JS5XpwcAo4CRgZ8pAWeep6HRAqy7ynAKcBUyJiDOABZRhRT4oaUQ9rtiyiL4l8B8R8TPKSLf/BNxKObH1Nf9NKN/BDylXzVsBRwD/BVzeEXDqGRAq/4u35HZWSzqVMnLvdyTtVK+r3TxZvgv4DHByRHyUchHwkqSvd6zT1+2sdXwdTBlc8ocRcWdETAV+AdzaERB6kf8ESnA5ISKmAV8GLpO0Rx0v1t4I3E25On8JmAnsLmmqpBG5H1vWY0OVIPCqpN0ljaNUUX4MCOBjkoZL2hF4V38FBAeD1xovaVPKieydlfQbgVci4neN3iFJB1Kq9L4BnCnpzRHxBDAPeJJykL6hxryqRfemiFgFPA/cBLw/It6daadSSh7dHngqddxPAbsCHwSIiGspVUVvoTyfok/HWl6pzaI882KKpJMrP/zn6GM7Sn4vrwLXUj7DAuDiiLiNEhweAM6XNLbOpcOO/9vtwFDgB5QTwHeAh6l/4/VI4Dhgj5z/HfCvue26qBxfu1K+t5eBv5T0llw+jfLZ/jPXq/nkJunNwL9Q9n/LrGr6DqWk8zf1OlFGxH/kNq4CroyIf6Ucz+8GDpJ0FvAV9bFxOaufTs2Lr0mU0s65wL8Dojzn5UXKheD/AC/1W1VlRPiVL+B0oI1SnD0XWAZ8KJedRCm2bdOA/VBlekvgfMpVEMAXgFZg15xvAob3Yhufptz+PgJoppzwPpnL3gfc07GNbvL5KOWH+CVKffeDlKvOjuVHACP7+H0cSblqXgxcTgmKS4HPUa4Q7wLe2Yf8N6lMj8ptPACcVknfEfgnYA4wuE7/58MpP/KzKc/vGA6MyGV75T7sWY9jiXKlOySnjwFeAQ7M+UPzmNq2euz19nukDCmzDWWwyaPzGL2EUnJ8S2X9HXqY//bAF4GvUy7OPgfsmMumAN+t03fV8Tm+Tjk5XwEMqvw2vko5Me9Rh2NgF8qFwN/lcf1Xmf6PmT6cEhQmA2+vx3HX1cvDUaRsvDuCcuKdBGxNuaqdRDlRHgS8Nxo4ZpKkfYD7KSWUU4HjIuL3Ko8FPQWYHBH/14t8TwQ+DhwTEU9kve3RQAulwXwwcGpE/LKbfI6hBIH3UwLBY5SqlcOBeRHxtZ7uWyfbGEn5/j8cEQ9mW85ISqn2TcCjwOKI+HEdtvURYHfKifLnwNeAf45SFYWkMcDvI6K9Dtt6KzCXchK7mPLdnUL54TdTTp6fiojr67CtI4HTKCWOn1FKAgdTSpbfo9SJXx+lNNdnkt4UEY9k+8vplJP2UErD+BPA9yLi/6ql1BrzHQRMpQSFYZTG3Ccpje2HAV+OiB/1cp+rJeYDgRXA0oh4UdKPgZcj4thcvhVARPymN9uqfp4o7SZvBr5J+Y4+ERF35/KvUtoq3hERT/dlWzXpz0izobwoV4O/ogyQB7AZ5Qrgs5SuXW8ir9gauE/NlKL0lZTSwXeAKyrLPwWM62XeM4GP5vRW+XcI5QQ7Ati6xnw+B3ym8v6PAhcAE4FbKD/YXl9pZr7Dgf8FDsj5TYHvUqpzjq2s19ftHAPcR+nW98+UktMs4F7g/Dr/b3ekBOMTKHXSt1EeOtJxLO4BNNdpW2+mlNb2ogTpzwAX5bITKPXh78v5XpV4WHNFrfzfv8qaUtuprCnV7kup4unRb4nSoeGknB6Uv80vUOrVF1AC2oF92ffK/N/ksXs5ZeTkcZl+HfATKqXIOv5/xlCqpW/Mc842leVf6+1n6+nLbQZARCwHPgm0SDohIl6m1BW2Uw7sFRHxbKP2R9LmEdEK3AAcQLn6/jmlPaMl9/mCiHi0hrw6+x8PJuuMY83VTQulCP9sRLxQ467eD7xN0oSIeCVKveqelEboyRHxXOQR3VsRsZJSMjhY0u4R8QdKvfoQ4EhV+q73ZTuU4volEXEXcCblJDkcOBE4QNJ2fcwf+GNJ5wzKdzSDUlX31xHxuMoT/04FHsj/fz0MojS03xkRN1COqW0lHRQRVwEfAb4naWKUtqIeq3z3m0TEYsrJeSjwNkqJ8X2SRkdpfzmzF7+l4cA5+dtcTfn/b0HpWXcPpRQ/pZf/o0FQrtIl7Uk58R5EqYaEfK5KREwBVlJKJX3S0a4haT9KQPsipZfVxyglthnKm84i4syI+O++brMmjYg4G8qLcuV0D2uuZDYB3tDgfXgHpU7yCMqP4HTKVeT7KI1936cXV3DAe4GjgN0o9bmPAOdQqoWmUoraO/Uwz2GUnhznUhrW3kOp59yuzt/J6NzXG3NbD1GuMudTh3rb3MZRlKu/CZW0/6KUlOp2NUg5+fyI0jvtIkop7S3AWym9V47sQ96iNA5vS6laPJ9SbfdTSjVbx3rfAE6vzL8P2KWPn+vA3M5w4GTKFe0gSjvLbygn8E3oZQmOUmd+N2tKMe/MPJvy814FNPUwz+0o1XPb5vwESsn265QSR0cby+F1/P93lKImU3pVnU9pf/gHSqlwLPDflPaVurRN1bxvjdzYhvDKf9JSKlUQ/by9tYupHX30vwX8mHKleEwu2xkY34ttHE1pGJ9NuWqbnCfyH1HqqxcBu/Vy/3egBKyfAP9Wr5NzJ9vZmlJ6+Syl22/HVWGfGqcr+XcW2Fp7eoJZR/6jOk64lGqiC/N7m0XpVXM9pVvua46JHm7n/cCzlKqhiZn215Qb6C4A3k4JpvvX87jNtC8BVwPHUy4KPsyaxs8xdfgOW4BnKFVNDwPvqizrbRXXkfl9DM/5KyjtKiNz/hTqcIEDbF+Z3oJSDdWS82+lBM8LKcH0z4F963Hc9WgfG73BDeGVJ4M3NXib0ylXCX+XJ4vN8sf7S2BVxw+7F/l+OANLE+VK7eg84I+srFNTG0E329kC2LJB39VBlJ5FdQ08/RXYKG0+F1B6o83IYHYRa3qOvIE1V6e9vXLu6AGzA6U95VGytw6ldLMH5QaqbwPvqeN3dhKlmuNj+Tn3y+/w5gxIPb546WZ7u+d32NETSr39zip5TqaUjLeiVNN8l3LRdC6lHalXF0qV/EVp86uWOi/KANDRS6mFUu36OWCLvhwLvd7PRm7Mry4PlvdTrnIPoVR9fA34i8pB8m1g5xrz0lp/z6O0e+yb8yMyIPwImFpdd0N5Ueptd+rH/Ose2Ch3NO9NuXL+PKU96nbqcMVc2cZRwJ2UK8szqHRNBUZ3dpz0Yhs7AENz+gxKUP4kpTfM4o7Pk8dyKz3sPjqAx9Rh+X1tQSnFnZxBp6bf3TryrXYTfwelXQpKW+DXgBNzfhfKkx5/Buw3IN/BQP8TNuZXXjFskif7jrrQLSltBpdW1tu01vwq0+NZc7X4eUqXvu1zvolSDbJB/FBfTy9Ke80bKSXAH5LVNX0NyJSG+7up1P1TSoA/p5QOnwD26uM2RlF6Wn2E0kD8teqJi1LPPbcjkJJ17hvKi9JmeB9ZSqtTnh0XZftnsFlGKalvlQHnauA/KFVVf05pO3j/QHx+D1TXYKoMOBXlKAlJbcBbJd0SZcCtLwILJP1ZRDwVpQdNt6Lj6JM+TrnSWSLpyYg4N+9Q/h9Jb4+IZZKujwEYZzCzeOUAAAWpSURBVGljF2vGtjlH0ucpJ4Sfd/zv+uBlSqngnZLeS+nJ8wSlB8xOwAcj4s4+buMJ4A5KVc1JlM4I76AMBwKlp9KbKD2xoNy/sMGIiBvyjuKb8h6f6Ov/JSIiew19hdIx5W5J/0s56XcMczMR+D9K4/FxlNqAhnPX0gaqDHmApMMkHZfj7VxHaSA9TNJ4SpvFZsBve7GNFkqf+SMpVxo7A0TEzNzOwrx5p68nH+ulypAJDwM7qT7jXS2lVMtMo7QzfYJyf8bFwKyI+ElfMq/clLUJpdfN0ZTeMGeoDHQIpS3kzynHMnUIcA0XEdcBb4uIV+u4/9tQgvNhOX8w8JfA3Ih4MSIWUaqnvkDpZvxwnbbbI74DeQDkj+csSvHwSMowuWMofdp3o/zgzoy8E7GbvN5OqT+/POePobQLvEq5yjgyIl7JewHuz/GI+nwHrfVNBoQjgEejmzu9e5jvkPx/v5VyF/MnIuKmOuV9EjnIHaXDw68pvbCOofSGejsNvkt/Q6EykONXgbMj4gpJm1FubvtoRNyT62wbESsGah9dTdRgefI+kDKWzlJJj1OK3hMj4lOS/owyIF6tB8Ug4OuSVkfE9yldSL8MPBcR++c2zwD2VBkN89f1/kzWc3nV2echNDqxOqs4/gX4fL0CQdoF+H5E3CXpTEq35wm5rXmU4bd9fHUiIq6T9AdK9eCQiLhE0gFZjTQoIlYPZCAAB4OGyuqAkyg/oGZJyyLiHyQF8Ehevdc01lDWQ24WEbeoPNNgTl5tXkmph9xa0gco/+MPAtOi3Fltr2NRxrp5kFI//WhPx//pxi8oQ5IvyKv/b2Rp4THKXfq13rm+UYqIBSojIn9F5eFUTwOrow8P+KknVxP1I0lviIgXc3oqpQfGtZQqot8CP4ocdkDSp4AbehAMjqQ0GK6KiKckvZMyouZnKHc0vo1y888zwL/WsyrCNk6ShlHG7oFyH8FQSrfSaVGGdLEarK9VtQ4G/UTlARWfpQx+d1uOtrkiIq7MRuMvUMbhvz4ift6DfP/YG0nSHpQ7S/8hIuarPKbvYmBmRMzLcYm0vlx52IZP0g6UxuOjKTdDfqajzts2bK4m6j+bU4bXnSbpd5TeO0MAsvvo31MalN4t6c6I+H13Ga7VG+lUShe+HwAfl/RqRFyv8gzi63Ldq/vlk9lGK8pDlf5F0iWUC40+DeNs6w+XDOpsrXHRd6VcQb2Rcufmcspt6FtTrqpepDyQvEdjlauMu38KZSyb5ZJmUO4+vSAiFqmMx/5URLTV63OZ2eubSwZ1tFYg2DTKw1guodzW/g7KuC0vUIYl2Jpy13FPA8FQylgqnwdeycAwmtKd9ItZjbSwbh/KzDYKLhnUyVqB4NOUsUeep4zk+CxlHJcdgW9ExEN96eWRJYGPUW40epAyHPUbc/7miHi8r5/HzDYuDgZ1lvcRfIkyNPFBwLGUcYBWUsauH0IZmfDlPgSDzSl3ez4cESuye990ypC4r/T9U5jZxsbBoI7yLsMPAD+NiAsz7SzK4wWPpoxUOaReN+Zkb6GTKd37TnT3UTPrLY9NVCeSmiljjowAdpX0RoCI+AplWOrvAS/V+Q7NzSnDThzvQGBmfeGSQS911Pl39PuX9CHK6JCbUh7gfSNlIKqncv0R0Q/PUa7zHaZmtpFyMOgjSeMjYkmOBPpeSkAYBuxFGdr3nyPimYHcRzOz7riaqA8k7QgskvSBvMt3HvAUZQTS+ygPHPHdv2a23nMw6IOI+BWly+inJJ0YEasi4hLKk8SeAab3R9WQmVm9+aazPoqIH0taDZyXN4Q9l4vmunrIzDYUDgZ1kEPT/pZyf8FLlMG7nhjg3TIzq5kbkOtI0haU55b8bqD3xcysJxwMzMzMDchmZuZgYGZmOBiYmRkOBmZmhoOBmZnhYGBmZjgYmJkZ8P8BpnbTAD+wEHkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmdYtdEt1bif",
        "colab_type": "code",
        "outputId": "342164b0-e674-4e9a-98b2-feafc6a6033d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 99, 81, 1)]       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 99, 81, 1)         324       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 89, 41, 16)        7232      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 89, 41, 16)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 89, 41, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 79, 21, 32)        118304    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 79, 21, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 79, 21, 32)        128       \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 79, 672)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 79, 256)           820224    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 79, 256)           1024      \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 79, 128)           164352    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 79, 128)           512       \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 79, 64)            41216     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 79, 64)            256       \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 79, 32)            10368     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 79, 32)            128       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2528)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               323712    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 12)                780       \n",
            "=================================================================\n",
            "Total params: 1,497,648\n",
            "Trainable params: 1,496,046\n",
            "Non-trainable params: 1,602\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZeVIY_qjLQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}